{
    "docs": [
        {
            "location": "/",
            "text": "Tungsten Fabric for Windows documentation",
            "title": "Home"
        },
        {
            "location": "/ci_admin_guide/List_of_VMs_in_Windows_CI/",
            "text": "List of all important VMs in Windows CI\n\n\n\n\n\n\nVMware:\n\n\n\n\nci-vc\n\n\nvCenter Server on Windows\n\n\nCritical\n\n\nREQUIRES BACKUP\n\n\n\n\n\n\nci-vc-um\n\n\nvCenter Update Manager\n\n\nREQUIRES BACKUP\n\n\n\n\n\n\n\n\n\n\n\n\nBase OS templates:\n\n\n\n\nWindows\n - Install OS (manually) + instruction (manually)\n\n\nPreferrably: automate\n\n\n\n\n\n\nCentOS\n - Prepared manually, no instruction\n\n\nTODO: Instruction with requirements\n\n\nRequirements:\n\n\nroot access SSH (password-based)\n\n\n2 NICs\n\n\nTODO: Verify if there are no more requirements\n\n\n\n\n\n\n\n\n\n\nUbuntu\n - No template, required to provision Ubuntu-based VMs\n\n\nTODO: Instruction/automation\n\n\nRequirements:\n\n\nciadmin\n user (SSH accessible, password-based)\n\n\npython3\n\n\n1 NIC\n\n\nTODO: Verify if there are no more requirements\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCI templates:\n\n\n\n\nbuilder\n - Ansible, Jenkins job\n\n\nRequires Windows template\n\n\n\n\n\n\ntester\n - Ansible, Jenkins job\n\n\nRequires Windows template \n\n\n\n\n\n\ntestbed\n - Ansible\n\n\nRequires Windows template\n\n\n\n\n\n\n\n\n\n\n\n\nInfra:\n\n\n\n\nbuilders\n - Ansible, Jenkins job\n\n\ntesters\n - Ansible, Jenkins job\n\n\nmgmt-dhcp\n - Created manually, DHCP server + configuration (172.17.0.0/24)\n\n\nimpact if down:\n\n\nwill cause failure in all production CI jobs due to lack of dhcp for testbed machines\n\n\nwill not affect demo-env, dev-env and other machines in public network\n\n\n\n\n\n\nfix cost:\n\n\nAutomate deployment\n\n\nBefore automation, backup\n\n\nVMware HA\n\n\n\n\n\n\n\n\n\n\nwinci-drive\n - Created manually, network drive with (probably) temporary content\n\n\nimpact if down: \n\n\nno impact on production CI\n\n\ndegrades debuggability of CI (cannot upload or use ready artifacts)\n\n\nimpacts ability to create builder templates\n\n\n\n\n\n\nfix cost:\n\n\nwill need to recreate directory structure and copy contents from one of the builders\n\n\nthis process is not documented to this degree of detail (no list of dependencies)\n\n\nBefore automation, backup\n\n\nVMware HA\n\n\n\n\n\n\n\n\n\n\nwinci-graphite\n - Created manually\n\n\nimpact if down:\n\n\nno impact on production CI\n\n\ndegrades CI monitoring\n\n\n\n\n\n\nfix cost:\n\n\nAutomate VM provisioning\n\n\nAutomate configuration and dashboard deployment\n\n\nBackup needed to preserve historical data\n\n\n\n\n\n\n\n\n\n\nwinci-monitoring\n - Created manually\n\n\nimpact if down:\n\n\nTODO: does this affect production job (namely - post stage will fail, right?)\n\n\n\n\n\n\nfix cost:\n\n\nTODO\n\n\n\n\n\n\n\n\n\n\nwinci-jenkins\n - Created manually, plugins + configuration\n\n\nimpact if down:\n\n\nABSOLUTELY CRITICAL\n\n\n\n\n\n\nfix cost:\n\n\nBACKUP\n\n\njob configuration\n\n\njob logs\n\n\nlogs server ssh keys\n\n\njenkins plugin list (initial version on contrail-windows-ci; need to check if works)\n\n\ncredentials\n\n\n\n\n\n\nAutomate configuration\n\n\nVMware HA\n\n\n\n\n\n\n\n\n\n\nwinci-mgmt\n - Created manually, Python requirements.txt have to be installed\n\n\nimpact if down:\n\n\nABSOLUTELY CRITICAL (cannot create testenvs)\n\n\n\n\n\n\nfix cost:\n\n\nAutomate provisioning \n\n\nUbuntu configured for Ansible\n\n\nUbuntu configured for Python tests\n\n\nUbuntu configured for monitoring scripts\n\n\n\n\n\n\nBackup\n\n\nansible-vault-key\n\n\nlogs server ssh keys\n\n\ngithub deploy ssh key\n\n\n\n\n\n\nVMware HA\n\n\n\n\n\n\n\n\n\n\nwinci-vyos-mgmt\n\n\nimpact if down:\n\n\nABSOLUTELY CRITICAL (cannot deploy contrail controllers)\n\n\n\n\n\n\nfix cost:\n\n\nBackup\n\n\nDocument configuration\n\n\nVMware HA\n\n\n\n\n\n\n\n\n\n\nwinci-zuulv2-production\n - Created manually with Ansible script\n\n\nimpact if down:\n\n\nABSOLUTELY CRITICAL (cannot run jobs)\n\n\n\n\n\n\nfix cost:\n\n\nAlready automated\n\n\nCreate prod and dev inventories for Zuul\n\n\n\n\n\n\nBackup:\n\n\ngerrit ssh keys\n\n\njenkins ssh keys\n\n\n\n\n\n\nVMware HA\n\n\n\n\n\n\n\n\n\n\nwinci-purgatory\n - Probably created manually? What is installed there?\n\n\nimpact if down:\n\n\nABSOLUTELY CRITICAL (cannot run jobs)\n\n\n\n\n\n\nfix cost:\n\n\npending PR for automation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHosts:\n\n\n\n\nesxi1-5\n\n\nfix cost:\n\n\nVMware HA on critical virtual machines\n\n\nbackup konfiguracji\n\n\n\n\n\n\n\n\n\n\nSSD/SATA drivers\n\n\nfix cost:\n\n\nTODO: Determine if servers can into RAID\n\n\nMaintenance to configure RAID\n\n\nIf not RAID, then shared storage for critical VMs is needed\n\n\nPreferrably some storage array with RAID configured\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNICs\n\n\nwe lack redundancy in case of main NIC failure\n\n\n\n\n\n\n\n\n\n\n\n\nBackup:\n\n\n\n\nAdditional storage space for backup, independent of VMware storage\n\n\nTODO: Backup method?\n\n\nTODO: Backup tool?\n\n\nTODO: Backup procedure?\n\n\nTODO: DR procedure for critical VMs?\n\n\nTODO: hardware monitoring?",
            "title": "List of all important VMs in Windows CI"
        },
        {
            "location": "/ci_admin_guide/List_of_VMs_in_Windows_CI/#list-of-all-important-vms-in-windows-ci",
            "text": "VMware:   ci-vc  vCenter Server on Windows  Critical  REQUIRES BACKUP    ci-vc-um  vCenter Update Manager  REQUIRES BACKUP       Base OS templates:   Windows  - Install OS (manually) + instruction (manually)  Preferrably: automate    CentOS  - Prepared manually, no instruction  TODO: Instruction with requirements  Requirements:  root access SSH (password-based)  2 NICs  TODO: Verify if there are no more requirements      Ubuntu  - No template, required to provision Ubuntu-based VMs  TODO: Instruction/automation  Requirements:  ciadmin  user (SSH accessible, password-based)  python3  1 NIC  TODO: Verify if there are no more requirements         CI templates:   builder  - Ansible, Jenkins job  Requires Windows template    tester  - Ansible, Jenkins job  Requires Windows template     testbed  - Ansible  Requires Windows template       Infra:   builders  - Ansible, Jenkins job  testers  - Ansible, Jenkins job  mgmt-dhcp  - Created manually, DHCP server + configuration (172.17.0.0/24)  impact if down:  will cause failure in all production CI jobs due to lack of dhcp for testbed machines  will not affect demo-env, dev-env and other machines in public network    fix cost:  Automate deployment  Before automation, backup  VMware HA      winci-drive  - Created manually, network drive with (probably) temporary content  impact if down:   no impact on production CI  degrades debuggability of CI (cannot upload or use ready artifacts)  impacts ability to create builder templates    fix cost:  will need to recreate directory structure and copy contents from one of the builders  this process is not documented to this degree of detail (no list of dependencies)  Before automation, backup  VMware HA      winci-graphite  - Created manually  impact if down:  no impact on production CI  degrades CI monitoring    fix cost:  Automate VM provisioning  Automate configuration and dashboard deployment  Backup needed to preserve historical data      winci-monitoring  - Created manually  impact if down:  TODO: does this affect production job (namely - post stage will fail, right?)    fix cost:  TODO      winci-jenkins  - Created manually, plugins + configuration  impact if down:  ABSOLUTELY CRITICAL    fix cost:  BACKUP  job configuration  job logs  logs server ssh keys  jenkins plugin list (initial version on contrail-windows-ci; need to check if works)  credentials    Automate configuration  VMware HA      winci-mgmt  - Created manually, Python requirements.txt have to be installed  impact if down:  ABSOLUTELY CRITICAL (cannot create testenvs)    fix cost:  Automate provisioning   Ubuntu configured for Ansible  Ubuntu configured for Python tests  Ubuntu configured for monitoring scripts    Backup  ansible-vault-key  logs server ssh keys  github deploy ssh key    VMware HA      winci-vyos-mgmt  impact if down:  ABSOLUTELY CRITICAL (cannot deploy contrail controllers)    fix cost:  Backup  Document configuration  VMware HA      winci-zuulv2-production  - Created manually with Ansible script  impact if down:  ABSOLUTELY CRITICAL (cannot run jobs)    fix cost:  Already automated  Create prod and dev inventories for Zuul    Backup:  gerrit ssh keys  jenkins ssh keys    VMware HA      winci-purgatory  - Probably created manually? What is installed there?  impact if down:  ABSOLUTELY CRITICAL (cannot run jobs)    fix cost:  pending PR for automation         Hosts:   esxi1-5  fix cost:  VMware HA on critical virtual machines  backup konfiguracji      SSD/SATA drivers  fix cost:  TODO: Determine if servers can into RAID  Maintenance to configure RAID  If not RAID, then shared storage for critical VMs is needed  Preferrably some storage array with RAID configured        NICs  we lack redundancy in case of main NIC failure       Backup:   Additional storage space for backup, independent of VMware storage  TODO: Backup method?  TODO: Backup tool?  TODO: Backup procedure?  TODO: DR procedure for critical VMs?  TODO: hardware monitoring?",
            "title": "List of all important VMs in Windows CI"
        },
        {
            "location": "/ci_admin_guide/Merge_development_to_production/",
            "text": "Merge development to production\n\n\nThis document describes the steps required to perform a merge from \ndevelopment\n to \nproduction\n in Contrail Windows CI.\n\n\nPre-merge check\n\n\nRun production pipeline on \ndevelopment\n branch\n\n\n\n\nPreferably freeze \n$commitId\n of \ndevelopment\n branch\n\n\nClone \nwinci-server2016-prod\n to \nwinci-prod-test\n\n\nChange \nwinci-prod-test\n configuration\n\n\nProperties content: \nBRANCH_NAME=$commitId\n\n\nBranches to build: \n$commitId\n\n\n\n\n\n\nRun \nwinci-prod-test\n\n\nParameters:\n\n\nZUUL_PROJECT=Juniper/contrail-controller\n\n\nZUUL_BRANCH=master\n\n\nZUUL_REF=None\n (it should literally be \nNone\n)\n\n\nZUUL_URL=http://10.84.12.75/merge-warrior\n\n\nZUUL_UUID=$someRandomUUID\n (e.g. $commitId with the first 8 characters replaced by \ndeadbeef\n)\n\n\nZUUL_CHANGE=\n (can be left empty)\n\n\nZUUL_PATCHSET=\n (can be left empty)\n\n\n\n\n\n\n\n\n\n\n\n\nMerge development to production\n\n\n\n\n\n\nUpdate production branch (following git operations require administrative privileges on GitHub)\n\n\nbash\ngit fetch --all --prune\ngit checkout development\ngit pull\ngit checkout production\ngit merge development\ngit push\n\n\n\n\n\n\nUpdate Zuul configuration\n\n\nbash\nlocalhost $ ssh winci-mgmt # with provided credentials; current address 10.84.12.25\nwinci-mgmt $ cd ~/ji/juniper-contrail-windows-ci\nwinci-mgmt $ git checkout production\nwinci-mgmt $ git pull\nwinci-mgmt $ git log\nwinci-mgmt $ cd ansible\nwinci-mgmt $ ansible-playbook -i ~/ji/ansible.hosts play.yml --vault-password-file ~/.ansible-vault\n\n\n\n\n\n\nZuul update playbook\n\n\n---\n- hosts: zuul\n  remote_user: ciadmin\n  become: yes\n  roles:\n  - zuul\n\n\n\n\nPost checks\n\n\n\n\n\n\nCheck Zuul services:\n\n\n\n\nzuul-merger\n\n\nzuul-server\n\n\n\n\nbash\nlocalhost $ ssh winci-zuulv2-production # with provided credentials; current address 10.84.12.75\nsystemctl status zuul-merger.service # should be active (running)\nsystemctl status zuul-server.service # should be active (running)\n\n\n\n\n\n\nTrigger Zuul job\n\n\n\n\nCreate a dummy PR on Gerrit\n\n\nPost \nrecheck windows\n on some existing PR\n\n\n\n\n\n\n\n\nFuture considerations\n\n\n\n\nSlave VM templates creation and promotion\n\n\nBuilder/tester deployment",
            "title": "Merge development to production"
        },
        {
            "location": "/ci_admin_guide/Merge_development_to_production/#merge-development-to-production",
            "text": "This document describes the steps required to perform a merge from  development  to  production  in Contrail Windows CI.",
            "title": "Merge development to production"
        },
        {
            "location": "/ci_admin_guide/Merge_development_to_production/#pre-merge-check",
            "text": "Run production pipeline on  development  branch   Preferably freeze  $commitId  of  development  branch  Clone  winci-server2016-prod  to  winci-prod-test  Change  winci-prod-test  configuration  Properties content:  BRANCH_NAME=$commitId  Branches to build:  $commitId    Run  winci-prod-test  Parameters:  ZUUL_PROJECT=Juniper/contrail-controller  ZUUL_BRANCH=master  ZUUL_REF=None  (it should literally be  None )  ZUUL_URL=http://10.84.12.75/merge-warrior  ZUUL_UUID=$someRandomUUID  (e.g. $commitId with the first 8 characters replaced by  deadbeef )  ZUUL_CHANGE=  (can be left empty)  ZUUL_PATCHSET=  (can be left empty)",
            "title": "Pre-merge check"
        },
        {
            "location": "/ci_admin_guide/Merge_development_to_production/#merge-development-to-production_1",
            "text": "Update production branch (following git operations require administrative privileges on GitHub)  bash\ngit fetch --all --prune\ngit checkout development\ngit pull\ngit checkout production\ngit merge development\ngit push    Update Zuul configuration  bash\nlocalhost $ ssh winci-mgmt # with provided credentials; current address 10.84.12.25\nwinci-mgmt $ cd ~/ji/juniper-contrail-windows-ci\nwinci-mgmt $ git checkout production\nwinci-mgmt $ git pull\nwinci-mgmt $ git log\nwinci-mgmt $ cd ansible\nwinci-mgmt $ ansible-playbook -i ~/ji/ansible.hosts play.yml --vault-password-file ~/.ansible-vault",
            "title": "Merge development to production"
        },
        {
            "location": "/ci_admin_guide/Merge_development_to_production/#zuul-update-playbook",
            "text": "---\n- hosts: zuul\n  remote_user: ciadmin\n  become: yes\n  roles:\n  - zuul",
            "title": "Zuul update playbook"
        },
        {
            "location": "/ci_admin_guide/Merge_development_to_production/#post-checks",
            "text": "Check Zuul services:   zuul-merger  zuul-server   bash\nlocalhost $ ssh winci-zuulv2-production # with provided credentials; current address 10.84.12.75\nsystemctl status zuul-merger.service # should be active (running)\nsystemctl status zuul-server.service # should be active (running)    Trigger Zuul job   Create a dummy PR on Gerrit  Post  recheck windows  on some existing PR",
            "title": "Post checks"
        },
        {
            "location": "/ci_admin_guide/Merge_development_to_production/#future-considerations",
            "text": "Slave VM templates creation and promotion  Builder/tester deployment",
            "title": "Future considerations"
        },
        {
            "location": "/ci_admin_guide/Run_gerrit_pipeline_on_github_PR/",
            "text": "Run gerrit pipeline on github PR\n\n\nWhen to do it:\n\n\nYou introduce a change to github/gerrit handling code, e.g. the\ntrigger mechanism - code that depends on Zuul or other Jenkins trigger plugins\n\n\n\n\n\n\nClone Jenkins job \nwinci-server2016-devel\n to some temporary \ntmp-devel-gerrit-check\n\n\nConfigure \ntmp-devel-gerrit-check\n:\n\n\nProperties content: BRANCH_NAME={branch to test}\n\n\nBranches to build: {branch to test}\n\n\nSchedule \ntmp-devel-gerrit-check\n job manually with parameters:\n\n\nZUUL_PROJECT=Juniper/contrail-controller\n\n\nZUUL_BRANCH=master\n\n\nZUUL_REF=None\n\n\nZUUL_URL=http://10.84.12.75/merge-warrior\n\n\nZUUL_UUID= (some random UUID - it will determine path on the logserver)\n\n\nZUUL_CHANGE= (can be left empty)\n\n\nZUUL_PATCHSET= (can be left empty)\n\n\nVerify that it passes\n\n\n(optional, recommended) Paste a link to successful build logs under your PR on github for the reviewers to verify\n\n\nRemove temporary \ntmp-devel-gerrit-check\n job",
            "title": "Run gerrit pipeline on github PR"
        },
        {
            "location": "/ci_admin_guide/Run_gerrit_pipeline_on_github_PR/#run-gerrit-pipeline-on-github-pr",
            "text": "When to do it:  You introduce a change to github/gerrit handling code, e.g. the\ntrigger mechanism - code that depends on Zuul or other Jenkins trigger plugins",
            "title": "Run gerrit pipeline on github PR"
        },
        {
            "location": "/ci_admin_guide/Update_Zuul/",
            "text": "Update Windows CI Zuulv2\n\n\nThis document describes a procedure required to update Windows CI Zuulv2 configuration.\nThis procedure updates configuration using \ndevelopment\n branch from \ncontrail-windows-ci\n repository.\n\n\nPrerequisites\n\n\n\n\nUbuntu 16.04 or Windows Subsystem for Linux with Ubuntu\n\n\nIt will serve as Ansible control machine\n\n\n\n\n\n\nUser's public SSH key installed on Zuulv2 instance\n\n\nPlease contact Windows CI team\n\n\n\n\n\n\nAccess to ansible vault key\n\n\nPlease contact Windows CI team\n\n\n\n\n\n\n\n\nSteps\n\n\n\n\n\n\nInstall required \napt\n dependencies on Ansible control machine\n\n\nbash\napt-get install git python3 python3-pip python3-virtualenv\n\n\n\n\n\n\nClone \ncontrail-windows-ci\n repository\n\n\nbash\ncd ~/\ngit clone https://github.com/Juniper/contrail-windows-ci.git\ncd contrail-windows-ci\n\n\n\n\n\n\nVerify that \ndevelopment\n branch contains PRs with required changes to Zuul configuration\n\n\n\n\nAssuming \nPR#2\n and \nPR#1\n are required PRs, run the following command:\n\n\n\n\nbash\ngit log --oneline\n\n\n\n\nOutput will contain a list of merged PRs, from newest to oldest. Required PRs should be at the top:\n\n\n\n\n```\nabcdabc PR#2\nabcd123 PR#1\ne8691f5 Some other PR\n3af841e Some other PR, part 2\n\n\n... omitted\n\n\n```\n\n\n\n\n\n\nMove to \nansible\n directory\n\n\nbash\ncd ansible\n\n\n\n\n\n\nCreate a virtualenv and install \npip\n dependencies\n\n\nbash\npython3 -m virtualenv -p /usr/bin/python3 venv\nsource venv/bin/activate\npip install -r python-requirements.txt\n\n\n\n\n\n\nCreate a file for Ansible vault key and populate it with the key\n\n\nbash\ntouch ~/ansible-vault-key\nvim ~/ansible-vault-key  # enter ansible vault key into a file\n\n\n\n\n\n\nTest connection to Zuul with Ansible\n\n\nbash\nansible -i inventory.prod --private-key=YOUR_PRIVATE_KEY zuul -m ping\n\n\n\n\nwhere \nYOUR_PRIVATE_KEY\n is a path to your SSH private key\n\n\n\n\n\n\n\n\nRun \nsetup-zuul-server.yml\n playbook\n\n\nbash\nansible-playbook -i inventory.prod --private-key=YOUR_PRIVATE_KEY setup-zuul-server.yml\n\n\nVerify that the run completed successfully.\nThe output should be following and \nfailed\n task count must equal zero.\n\n\n```\n\n\n\n\ntask list omitted for brevity\n\n\n\n\nPLAY RECAP \n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n10.84.12.75                : ok=22   changed=2    unreachable=0    failed=0\n\n\n\n\n... - task run time omitted for brevity\n\n\n\n\n```\n\n\n\n\nfailed\n task count should be equal to zero",
            "title": "Update Windows CI Zuulv2"
        },
        {
            "location": "/ci_admin_guide/Update_Zuul/#update-windows-ci-zuulv2",
            "text": "This document describes a procedure required to update Windows CI Zuulv2 configuration.\nThis procedure updates configuration using  development  branch from  contrail-windows-ci  repository.",
            "title": "Update Windows CI Zuulv2"
        },
        {
            "location": "/ci_admin_guide/Update_Zuul/#prerequisites",
            "text": "Ubuntu 16.04 or Windows Subsystem for Linux with Ubuntu  It will serve as Ansible control machine    User's public SSH key installed on Zuulv2 instance  Please contact Windows CI team    Access to ansible vault key  Please contact Windows CI team",
            "title": "Prerequisites"
        },
        {
            "location": "/ci_admin_guide/Update_Zuul/#steps",
            "text": "Install required  apt  dependencies on Ansible control machine  bash\napt-get install git python3 python3-pip python3-virtualenv    Clone  contrail-windows-ci  repository  bash\ncd ~/\ngit clone https://github.com/Juniper/contrail-windows-ci.git\ncd contrail-windows-ci    Verify that  development  branch contains PRs with required changes to Zuul configuration   Assuming  PR#2  and  PR#1  are required PRs, run the following command:   bash\ngit log --oneline   Output will contain a list of merged PRs, from newest to oldest. Required PRs should be at the top:   ```\nabcdabc PR#2\nabcd123 PR#1\ne8691f5 Some other PR\n3af841e Some other PR, part 2",
            "title": "Steps"
        },
        {
            "location": "/ci_admin_guide/Update_Zuul/#omitted",
            "text": "```    Move to  ansible  directory  bash\ncd ansible    Create a virtualenv and install  pip  dependencies  bash\npython3 -m virtualenv -p /usr/bin/python3 venv\nsource venv/bin/activate\npip install -r python-requirements.txt    Create a file for Ansible vault key and populate it with the key  bash\ntouch ~/ansible-vault-key\nvim ~/ansible-vault-key  # enter ansible vault key into a file    Test connection to Zuul with Ansible  bash\nansible -i inventory.prod --private-key=YOUR_PRIVATE_KEY zuul -m ping   where  YOUR_PRIVATE_KEY  is a path to your SSH private key     Run  setup-zuul-server.yml  playbook  bash\nansible-playbook -i inventory.prod --private-key=YOUR_PRIVATE_KEY setup-zuul-server.yml  Verify that the run completed successfully.\nThe output should be following and  failed  task count must equal zero.  ```",
            "title": "... omitted"
        },
        {
            "location": "/ci_admin_guide/Update_Zuul/#task-list-omitted-for-brevity",
            "text": "",
            "title": "task list omitted for brevity"
        },
        {
            "location": "/ci_admin_guide/Update_Zuul/#-task-run-time-omitted-for-brevity",
            "text": "",
            "title": "... - task run time omitted for brevity"
        },
        {
            "location": "/ci_admin_guide/Update_zuul_layout/",
            "text": "Update Zuul layout\n\n\nZuul is a triggering mechanism for Windows CI. It listens for events sent by Gerrit.\nSome events make Zuul trigger specific Jenkins jobs. \nZuul knows which events on which projects should trigger which jobs thanks to a config file.\nThis config file must be updated when:\n\n one wants to add a project on Gerrit\n\n one wants to change which jobs run on existing projects\n\n\nFor now, update process has 2 steps:\n1. Commit updated \nlayout.yaml\n file to specific Windows CI git repository.\n2. Reload Zuul configuration.\n\n\n1. Commit updated \nlayout.yaml\n file to specific Windows CI git repository.\n\n\n\n\nClone \ngithub.com/Juniper/contrail-windows-ci\n repository.\n\n\n\n\ngit clone https://github.com/Juniper/contrail-windows-ci\n\n\n\n\n\n\nRun \nupdate-zuul-layout.py\n script from \nansible\n directory.\n\n\n\n\ncd ansible\npython .\\update-zuul-layout.py\n\n\n\n\n\n\nVerify what changed in the \nansible/roles/zuul/files/layout.yaml\n file:\n\n\n\n\ngit diff\n# verify what changed\n\n\n\n\n\n\n(Optional) Make any \"manual\" changes to \nansible/roles/zuul/files/layout.yaml\n file. Do not modify automatically generated lines.\n\n\nCommit the changes.\n\n\nOpen a PR to \ndevelopment\n branch of \ngithub.com/Juniper/contrail-windows-ci\n.\n\n\nWait for CI checks to pass.\n\n\nAdd one of Windows team members as reviewers.\n\n\n\n\n2. Reload Zuul configuration.\n\n\n\n\nSSH to the \nwinci-mgmt\n machine using provided credentials.\n\n\n\n\nlocalhost $ ssh SOME_USER@10.84.12.25\n\n\n\n\n\n\nCheckout newest version of \ndevelopment\n branch of \ngithub.com/Juniper/contrail-windows-ci\n.\n\n\n\n\nwinci-mgmt $ cd ~/ji/juniper-contrail-windows-ci\nwinci-mgmt $ git checkout development\nwinci-mgmt $ git pull\n\n\n\n\n\n\nVerify that commit with updated \nlayout.yaml\n is present.\n\n\n\n\nwinci-mgmt $ git log\n\n\n\n\n\n\nRun an ansible playbook that will update and reload Zuul daemon.\n\n\n\n\nwinci-mgmt $ cd ansible\nwinci-mgmt $ ansible-playbook -i ~/ji/ansible.hosts play.yml --vault-password-file ~/.ansible-vault",
            "title": "Update Zuul layout"
        },
        {
            "location": "/ci_admin_guide/Update_zuul_layout/#update-zuul-layout",
            "text": "Zuul is a triggering mechanism for Windows CI. It listens for events sent by Gerrit.\nSome events make Zuul trigger specific Jenkins jobs. \nZuul knows which events on which projects should trigger which jobs thanks to a config file.\nThis config file must be updated when:  one wants to add a project on Gerrit  one wants to change which jobs run on existing projects  For now, update process has 2 steps:\n1. Commit updated  layout.yaml  file to specific Windows CI git repository.\n2. Reload Zuul configuration.",
            "title": "Update Zuul layout"
        },
        {
            "location": "/ci_admin_guide/Update_zuul_layout/#1-commit-updated-layoutyaml-file-to-specific-windows-ci-git-repository",
            "text": "Clone  github.com/Juniper/contrail-windows-ci  repository.   git clone https://github.com/Juniper/contrail-windows-ci   Run  update-zuul-layout.py  script from  ansible  directory.   cd ansible\npython .\\update-zuul-layout.py   Verify what changed in the  ansible/roles/zuul/files/layout.yaml  file:   git diff\n# verify what changed   (Optional) Make any \"manual\" changes to  ansible/roles/zuul/files/layout.yaml  file. Do not modify automatically generated lines.  Commit the changes.  Open a PR to  development  branch of  github.com/Juniper/contrail-windows-ci .  Wait for CI checks to pass.  Add one of Windows team members as reviewers.",
            "title": "1. Commit updated layout.yaml file to specific Windows CI git repository."
        },
        {
            "location": "/ci_admin_guide/Update_zuul_layout/#2-reload-zuul-configuration",
            "text": "SSH to the  winci-mgmt  machine using provided credentials.   localhost $ ssh SOME_USER@10.84.12.25   Checkout newest version of  development  branch of  github.com/Juniper/contrail-windows-ci .   winci-mgmt $ cd ~/ji/juniper-contrail-windows-ci\nwinci-mgmt $ git checkout development\nwinci-mgmt $ git pull   Verify that commit with updated  layout.yaml  is present.   winci-mgmt $ git log   Run an ansible playbook that will update and reload Zuul daemon.   winci-mgmt $ cd ansible\nwinci-mgmt $ ansible-playbook -i ~/ji/ansible.hosts play.yml --vault-password-file ~/.ansible-vault",
            "title": "2. Reload Zuul configuration."
        },
        {
            "location": "/contrail_deployment/contrail_ansible_deployer/",
            "text": "A few words about contrail deployment in Windows CI\n\n\nEnvironment\n\n\n\n\nPlaybooks\n\n\n\n\nprovision_instances.yml - creates server instances (e.g. on AWS) not used in Contrail Windows CI\n\n\nconfigure_instances.yml - installs dependencies installs and starts docker\n\n\ninstall_contrail.yml - installs Contrail and installs orchestrator (optional)\n\n\n\n\nConfiguration\n\n\n\n\nOrchestrators:\n\n\nNone\n\n\nOpenStack\n\n\nVCenter\n\n\nContrail version and kolla version:\n\n\nocata-master-91 and ocata\n\n\nDocker registry\n\n\nci-repo.englab.juniper.net or \nopencontrailnigthly\n\n\nInterfaces\n\n\nExample \nconfig\n\n\nWindows-CI \nconfig\n\n\n\n\nKolla\n\n\n\n\nKolla == production-ready containers and deployment tools for operating OpenStack\n\n\ncontrail-ansible-deployer internally clones Juniper/contrail-kolla-ansible (branch: contrail/ocata)\n\n\nBugs which may affect us can be introduced in contrail-ansible-deployer as well as in contrail-kolla-ansible\n\n\n\n\nBase image\n\n\n\n\nCentOS 7.4 (kernel >= 3.10.0-693.17.1)\n\n\nTwo interfaces:\n\n\nControl Plane\n\n\nData Plane\n\n\nIP address is required on every interface - can be static\n\n\nMore information:\n\n\nhttps://github.com/Juniper/contrail-ansible-deployer#prerequisites\n\n\n\n\nWindows-CI\n\n\n\n\nTroubleshooting\n\n\n\n\nTry to run playbook locally from laptop\n\n\nTry to look for similar issue on contra-cloud.slack channel: contrail-ansible\n\n\nCheck recent commits in contrail-ansible-deployer and contrail-kolla-deployer\n\n\nAsk our devops team\n\n\nAsk on slack channel\n\n\n\n\nZuul V3\n\n\n\n\nController image from pull request\n\n\nCorrect version of contrail-ansible-deployer\n\n\nCorrect version of contrail-kolla-deployer\n\n\nEnable voting on contrail-ansible-deployer and contrail-kolla-deployer",
            "title": "A few words about contrail deployment in Windows CI"
        },
        {
            "location": "/contrail_deployment/contrail_ansible_deployer/#a-few-words-about-contrail-deployment-in-windows-ci",
            "text": "",
            "title": "A few words about contrail deployment in Windows CI"
        },
        {
            "location": "/contrail_deployment/contrail_ansible_deployer/#environment",
            "text": "",
            "title": "Environment"
        },
        {
            "location": "/contrail_deployment/contrail_ansible_deployer/#playbooks",
            "text": "provision_instances.yml - creates server instances (e.g. on AWS) not used in Contrail Windows CI  configure_instances.yml - installs dependencies installs and starts docker  install_contrail.yml - installs Contrail and installs orchestrator (optional)",
            "title": "Playbooks"
        },
        {
            "location": "/contrail_deployment/contrail_ansible_deployer/#configuration",
            "text": "Orchestrators:  None  OpenStack  VCenter  Contrail version and kolla version:  ocata-master-91 and ocata  Docker registry  ci-repo.englab.juniper.net or  opencontrailnigthly  Interfaces  Example  config  Windows-CI  config",
            "title": "Configuration"
        },
        {
            "location": "/contrail_deployment/contrail_ansible_deployer/#kolla",
            "text": "Kolla == production-ready containers and deployment tools for operating OpenStack  contrail-ansible-deployer internally clones Juniper/contrail-kolla-ansible (branch: contrail/ocata)  Bugs which may affect us can be introduced in contrail-ansible-deployer as well as in contrail-kolla-ansible",
            "title": "Kolla"
        },
        {
            "location": "/contrail_deployment/contrail_ansible_deployer/#base-image",
            "text": "CentOS 7.4 (kernel >= 3.10.0-693.17.1)  Two interfaces:  Control Plane  Data Plane  IP address is required on every interface - can be static  More information:  https://github.com/Juniper/contrail-ansible-deployer#prerequisites",
            "title": "Base image"
        },
        {
            "location": "/contrail_deployment/contrail_ansible_deployer/#windows-ci",
            "text": "",
            "title": "Windows-CI"
        },
        {
            "location": "/contrail_deployment/contrail_ansible_deployer/#troubleshooting",
            "text": "Try to run playbook locally from laptop  Try to look for similar issue on contra-cloud.slack channel: contrail-ansible  Check recent commits in contrail-ansible-deployer and contrail-kolla-deployer  Ask our devops team  Ask on slack channel",
            "title": "Troubleshooting"
        },
        {
            "location": "/contrail_deployment/contrail_ansible_deployer/#zuul-v3",
            "text": "Controller image from pull request  Correct version of contrail-ansible-deployer  Correct version of contrail-kolla-deployer  Enable voting on contrail-ansible-deployer and contrail-kolla-deployer",
            "title": "Zuul V3"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/",
            "text": "HNS errors bestiary\n\n\nHNS error messages ofter aren't descriptive enough, and the cleanup is quite hard.\nThe following document describes common cleanup techniques and error interpretations.\n\n\nHNS Decontamination procedures\n\n\nBefore working with HNS, one must realize the risks.\nThere are many ways in which HNS can stop working and affect other parts of the system.\nFor a developer, it is important to be able to recognize those, which can be recovered \nfrom. Below are some techniques which may help.\n\n\nAlways try cleaning using the lowest level procedure. The higher the level, the more \npotential damage the cleanup can cause.\n\n\nA word of caution\n\n\nNever\n develop HNS on a baremetal or own laptop.\n\n\nLevel Alpha decontamination procedure\n\n\n\n\nFirst, stop the docker service.\n\n\n\n\nStop-Service docker\n\n\n\n\n\n\nRemove all virtual switches, container networks and NAT\n\n\n\n\nGet-ContainerNetwork | Remove-ContainerNetwork\nGet-VMSwitch | Remove-VMSwitch\nGet-NetNAT | Remove-NetNAT\n\n\n\n\n\n\nRestart HNS and docker services.\n\n\n\n\nRestart-Service hns\nRestart-Service docker\n\n\n\n\nLevel Beta decontamination procedure\n\n\n\n\nRemove all container networks. Always do this because some vmswitches may not be removed properly if you just execute the next command.\n\n\n\n\nGet-ContainerNetwork | Remove-ContainerNetwork\n\n\n\n\n\n\nManually remove \nHNS.data\n file. \nnet\n command sometimes works better at restarting HNS than PowerShell's \nRestart-Service\n.\n\n\n\n\n\n\nWarning: this is not recommended by Microsoft, but they do it in their official cleanup script, so I guess it's not that bad.\n\n\n\n\nnet stop hns; \ndel C:\\programdata\\Microsoft\\Windows\\HNS\\HNS.data; \nnet start hns;\n\n\n\n\nLevel Gamma decontamination procedure\n\n\nUse official Microsoft script to cleanup. It will also cleanup some registry entries and do much more.\n\n\nhttps://github.com/MicrosoftDocs/Virtualization-Documentation/tree/live/windows-server-container-tools/CleanupContainerHostNetworking\n\n\nLevel [REDACTED] decontamination procedure\n\n\nEverything is lost. All we can do wipe all devices and hope that the contamination won't spread to other hosts.\n\n\n\n\nWarning: this might BSOD.\n\n\n\n\n// perform as single command because you will lose connectivity during netcfg -D\nnetcfg -D; Restart-Computer -force\n\n\n\n\nHNS error specimen list\n\n\nThe following chapter contains a list of HNS errors encountered throughout development, along with reproduction methods and natural habitat.\n\n\n1. HNS Unspecified Error\n\n\nNatural habitat:\n\n\n\n\n\n\nWhen attempting to create a transparent HNS network\n\n\n\n\nwhen creation of another network or VMSwitch is already in progress\n  (eg. we've just started Docker service and it tries to create the NAT network).\n\n\n\n\nWe can work around this bug by retrying after a few seconds.\n\n\n\n\n\n\nReproduction:\n\n\nTry to create multiple HNS networks in a loop simultaneously with multiple processes.\nWe suspect that this error occurs during a high load.\n\n\n2. HNS Invalid Parameter\n\n\nNatural habitat:\n\n\nTODO\n\n\nReproduction:\n\n\nTODO\n\n\n3. HNS Element not found\n\n\nNatural habitat:\n\n\n\n\n[Hypothesis] When attempting to create a transparent docker network\n\n\nwhen no other transparent docker network exists and\n\n\nEthernet adapter to be used by the transparent networks has no IP address or it's invalid.\n\n\n\n\n\n\n\n\nReproduction:\n\n\nSee https://github.com/Microsoft/hcsshim/issues/95\n\n\n4. HNS failed with error : {Object Exists} An attempt was made to create an object and the object name already exists\n\n\nNatural habitat:\n\n\nThis error probably happens when docker tries to create NAT network, but HNS left over some trash after last NAT network.\n\n\nCleanup everything as explained in the Decontamination Procedures chapter. If the problem still persists, just create a random NAT network:\n\n\nNew-ContainerNetwork foo\n\n\n\n\nReproduction:\n\n\nTODO\n\n\n5. Container creation fails with error: CreateContainer: failure in a Windows system call\n\n\nNatural habitat:\n\n\nThis error happens occasionally when Docker tries to create a container.\n\n\nThe container is actually created (it enters CREATED state), but can not be run (Docker doesn't start it automatically and manual start fails). Such a faulty container can be removed. Then one may try to create container again - this is expected to succeed (no case has been observed, when second attempt failed).\n\n\nReproduction:\n\n\nThere's no obvious correlation with any special circumstances. On a VM that's not heavily loaded, it is expected that hundreds of tries might be needed to reproduce this error. Creating and removing containers in a loop is enough.",
            "title": "HNS errors bestiary"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#hns-errors-bestiary",
            "text": "HNS error messages ofter aren't descriptive enough, and the cleanup is quite hard.\nThe following document describes common cleanup techniques and error interpretations.",
            "title": "HNS errors bestiary"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#hns-decontamination-procedures",
            "text": "Before working with HNS, one must realize the risks.\nThere are many ways in which HNS can stop working and affect other parts of the system.\nFor a developer, it is important to be able to recognize those, which can be recovered \nfrom. Below are some techniques which may help.  Always try cleaning using the lowest level procedure. The higher the level, the more \npotential damage the cleanup can cause.",
            "title": "HNS Decontamination procedures"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#a-word-of-caution",
            "text": "Never  develop HNS on a baremetal or own laptop.",
            "title": "A word of caution"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#level-alpha-decontamination-procedure",
            "text": "First, stop the docker service.   Stop-Service docker   Remove all virtual switches, container networks and NAT   Get-ContainerNetwork | Remove-ContainerNetwork\nGet-VMSwitch | Remove-VMSwitch\nGet-NetNAT | Remove-NetNAT   Restart HNS and docker services.   Restart-Service hns\nRestart-Service docker",
            "title": "Level Alpha decontamination procedure"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#level-beta-decontamination-procedure",
            "text": "Remove all container networks. Always do this because some vmswitches may not be removed properly if you just execute the next command.   Get-ContainerNetwork | Remove-ContainerNetwork   Manually remove  HNS.data  file.  net  command sometimes works better at restarting HNS than PowerShell's  Restart-Service .    Warning: this is not recommended by Microsoft, but they do it in their official cleanup script, so I guess it's not that bad.   net stop hns; \ndel C:\\programdata\\Microsoft\\Windows\\HNS\\HNS.data; \nnet start hns;",
            "title": "Level Beta decontamination procedure"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#level-gamma-decontamination-procedure",
            "text": "Use official Microsoft script to cleanup. It will also cleanup some registry entries and do much more.  https://github.com/MicrosoftDocs/Virtualization-Documentation/tree/live/windows-server-container-tools/CleanupContainerHostNetworking",
            "title": "Level Gamma decontamination procedure"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#level-redacted-decontamination-procedure",
            "text": "Everything is lost. All we can do wipe all devices and hope that the contamination won't spread to other hosts.   Warning: this might BSOD.   // perform as single command because you will lose connectivity during netcfg -D\nnetcfg -D; Restart-Computer -force",
            "title": "Level [REDACTED] decontamination procedure"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#hns-error-specimen-list",
            "text": "The following chapter contains a list of HNS errors encountered throughout development, along with reproduction methods and natural habitat.",
            "title": "HNS error specimen list"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#1-hns-unspecified-error",
            "text": "",
            "title": "1. HNS Unspecified Error"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#natural-habitat",
            "text": "When attempting to create a transparent HNS network   when creation of another network or VMSwitch is already in progress\n  (eg. we've just started Docker service and it tries to create the NAT network).   We can work around this bug by retrying after a few seconds.",
            "title": "Natural habitat:"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#reproduction",
            "text": "Try to create multiple HNS networks in a loop simultaneously with multiple processes.\nWe suspect that this error occurs during a high load.",
            "title": "Reproduction:"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#2-hns-invalid-parameter",
            "text": "",
            "title": "2. HNS Invalid Parameter"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#natural-habitat_1",
            "text": "TODO",
            "title": "Natural habitat:"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#reproduction_1",
            "text": "TODO",
            "title": "Reproduction:"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#3-hns-element-not-found",
            "text": "",
            "title": "3. HNS Element not found"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#natural-habitat_2",
            "text": "[Hypothesis] When attempting to create a transparent docker network  when no other transparent docker network exists and  Ethernet adapter to be used by the transparent networks has no IP address or it's invalid.",
            "title": "Natural habitat:"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#reproduction_2",
            "text": "See https://github.com/Microsoft/hcsshim/issues/95",
            "title": "Reproduction:"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#4-hns-failed-with-error-object-exists-an-attempt-was-made-to-create-an-object-and-the-object-name-already-exists",
            "text": "",
            "title": "4. HNS failed with error : {Object Exists} An attempt was made to create an object and the object name already exists"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#natural-habitat_3",
            "text": "This error probably happens when docker tries to create NAT network, but HNS left over some trash after last NAT network.  Cleanup everything as explained in the Decontamination Procedures chapter. If the problem still persists, just create a random NAT network:  New-ContainerNetwork foo",
            "title": "Natural habitat:"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#reproduction_3",
            "text": "TODO",
            "title": "Reproduction:"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#5-container-creation-fails-with-error-createcontainer-failure-in-a-windows-system-call",
            "text": "",
            "title": "5. Container creation fails with error: CreateContainer: failure in a Windows system call"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#natural-habitat_4",
            "text": "This error happens occasionally when Docker tries to create a container.  The container is actually created (it enters CREATED state), but can not be run (Docker doesn't start it automatically and manual start fails). Such a faulty container can be removed. Then one may try to create container again - this is expected to succeed (no case has been observed, when second attempt failed).",
            "title": "Natural habitat:"
        },
        {
            "location": "/developer_guide/HNS_error_bestiary/#reproduction_4",
            "text": "There's no obvious correlation with any special circumstances. On a VM that's not heavily loaded, it is expected that hundreds of tries might be needed to reproduce this error. Creating and removing containers in a loop is enough.",
            "title": "Reproduction:"
        },
        {
            "location": "/developer_guide/building/Dockerized_builder_using_ansible/",
            "text": "Dockerized builder using ansible\n\n\nThis document describes what \nwould\n be needed create\na builder docker image (for building vrouter agent and extension)\nby reusing \nansible\n scripts that are already used in\nthe \ncontrail-windows-ci\n repository to deploy builder machines.\n\n\nThis method of building is not yet supported, but this document\ndescribes the steps needed to make it work. It also tries to\nlist the potential obstacles.\n\n\nThis document describes the process from the developer's point\nof view, but it could be adapted to running in CI too.\n\n\nWindows\n\n\nCurrently, this process is supported only for Windows machines.\n\n\nDocker\n\n\nInstall \nDocker Community Edition for Windows\n. Note that:\n\n\n\n\nYou need to sign in / create to accout to download the installer.\n\n\nYou need to choose windows containers (not linux) when installing.\n\n\n\n\nTODO: Is there another installation method?\n\n\nAnsible\n\n\nTo execute ansible on Windows Docker containers you need to have:\n\n\n\n\nA container image prepared for connecting via ansible to.\n\n\nA (virtual) linux machine to run ansible.\n\n\n(Optionally) To troubleshoot remote connection to container,\n   you need to have the container IP in \ntrusted hosts lists\n.\n   Depending on the configuration of your system, this may require\n   changing the policy in your domain.\n\n\n\n\nPreparing container for ansible\n\n\nNotes:\n\n\n\n\nPerhaps there exists a ready container prepared for ansible?\n\n\nThere exists an example script \nConfigureRemotingForAnsible.ps1\n.\n  Unfortunately, the \nmicrosoft/windowsservercore\n image does not have the firewall\n  service used by the script, so steps in this scripts need to be run manually.\n  This wasn't finished, and it needs some additional investigation.\n\n\n\n\nMachine for ansible\n\n\nThe preferred way to use ansible on windows machine is to use\nthe Linux Subsystem on Windows. You can install \nUbuntu 18.04\nfrom the Windows Store\n. (18.04 version is\nneeded for the ansible 2.4 to be available. On the older\nversion you can probably install ansible using pip)\n\n\n\n\nNote: Alternatively, you can install ansible and its dependencies also\nusing \nthis python-requirements.txt file\n\nfrom \ncontrail-windows-ci\n repository with\n\npip install -r python-requirements.txt\n\n\n\n\nInstall ansible >= 2.4 using \napt\n:\n\n\nsudo apt install ansible\n\n\n\n\nThere are additional python packages that need to be installed\nto let ansible connect to Windows machine:\n\n\nsudo apt install python-requests\nsudo apt install python-pip\npip install pywinrm\npip install requests-credssp\n\n\n\n\nThe \ngroup_vars/windows\n also need to be configured for windows:\nNOTE: \ngroup_vars\n, inventory and other scripts would be\nalready prepared, so this step won't be needed for the end user.\n\n\nansible_port: 5986\nansible_connection: winrm\nansible_winrm_transport: credssp\nansible_winrm_server_cert_validation: ignore\nansible_winrm_operation_timeout_sec: 60\nansible_winrm_read_timeout_sec: 120\nansible_user: Administrator@localhost\nansible_password: 'hunter2'\n\n\n\n\nContainer components\n\n\nBuild tools and .NET\n\n\nInstallation of .NET on \nmicrosoft/windowsservercore\n is not supported,\nbut microsoft provides the \nmicrosoft/dotnet-framework\n image.\n\n\nTODO: Do we need to install multiple .NET versions? If not,\nthis image would be sufficient.\n\n\nThe build tools can be installed on the container following\nthe instruction on \nthis page in microsoft docs\n.\nUnfortunately, I haven't managed to finish it, due to some\nHCS errors. Perhaps it was related to insufficient disk\nspace (before running the Dockerfile I had 50GB free space).\nPerhaps there is some other way of installing build tools,\nwhich I haven't tested.\n\n\nTroubleshooting\n\n\nWhen encountering weird errors in \ndocker build\n\n(the errors may come from HCS), it's probable that they're caused by:\n\n\n\n\nInsufficient available RAM/swap on the host machine.\n\n\nInsufficient RAM assigned to container.\n\n\nInsufficient disk space on the host machine.\n\n\nInsufficient disk space assigned to container.",
            "title": "Dockerized builder using ansible"
        },
        {
            "location": "/developer_guide/building/Dockerized_builder_using_ansible/#dockerized-builder-using-ansible",
            "text": "This document describes what  would  be needed create\na builder docker image (for building vrouter agent and extension)\nby reusing  ansible  scripts that are already used in\nthe  contrail-windows-ci  repository to deploy builder machines.  This method of building is not yet supported, but this document\ndescribes the steps needed to make it work. It also tries to\nlist the potential obstacles.  This document describes the process from the developer's point\nof view, but it could be adapted to running in CI too.",
            "title": "Dockerized builder using ansible"
        },
        {
            "location": "/developer_guide/building/Dockerized_builder_using_ansible/#windows",
            "text": "Currently, this process is supported only for Windows machines.",
            "title": "Windows"
        },
        {
            "location": "/developer_guide/building/Dockerized_builder_using_ansible/#docker",
            "text": "Install  Docker Community Edition for Windows . Note that:   You need to sign in / create to accout to download the installer.  You need to choose windows containers (not linux) when installing.   TODO: Is there another installation method?",
            "title": "Docker"
        },
        {
            "location": "/developer_guide/building/Dockerized_builder_using_ansible/#ansible",
            "text": "To execute ansible on Windows Docker containers you need to have:   A container image prepared for connecting via ansible to.  A (virtual) linux machine to run ansible.  (Optionally) To troubleshoot remote connection to container,\n   you need to have the container IP in  trusted hosts lists .\n   Depending on the configuration of your system, this may require\n   changing the policy in your domain.",
            "title": "Ansible"
        },
        {
            "location": "/developer_guide/building/Dockerized_builder_using_ansible/#preparing-container-for-ansible",
            "text": "Notes:   Perhaps there exists a ready container prepared for ansible?  There exists an example script  ConfigureRemotingForAnsible.ps1 .\n  Unfortunately, the  microsoft/windowsservercore  image does not have the firewall\n  service used by the script, so steps in this scripts need to be run manually.\n  This wasn't finished, and it needs some additional investigation.",
            "title": "Preparing container for ansible"
        },
        {
            "location": "/developer_guide/building/Dockerized_builder_using_ansible/#machine-for-ansible",
            "text": "The preferred way to use ansible on windows machine is to use\nthe Linux Subsystem on Windows. You can install  Ubuntu 18.04\nfrom the Windows Store . (18.04 version is\nneeded for the ansible 2.4 to be available. On the older\nversion you can probably install ansible using pip)   Note: Alternatively, you can install ansible and its dependencies also\nusing  this python-requirements.txt file \nfrom  contrail-windows-ci  repository with pip install -r python-requirements.txt   Install ansible >= 2.4 using  apt :  sudo apt install ansible  There are additional python packages that need to be installed\nto let ansible connect to Windows machine:  sudo apt install python-requests\nsudo apt install python-pip\npip install pywinrm\npip install requests-credssp  The  group_vars/windows  also need to be configured for windows:\nNOTE:  group_vars , inventory and other scripts would be\nalready prepared, so this step won't be needed for the end user.  ansible_port: 5986\nansible_connection: winrm\nansible_winrm_transport: credssp\nansible_winrm_server_cert_validation: ignore\nansible_winrm_operation_timeout_sec: 60\nansible_winrm_read_timeout_sec: 120\nansible_user: Administrator@localhost\nansible_password: 'hunter2'",
            "title": "Machine for ansible"
        },
        {
            "location": "/developer_guide/building/Dockerized_builder_using_ansible/#container-components",
            "text": "",
            "title": "Container components"
        },
        {
            "location": "/developer_guide/building/Dockerized_builder_using_ansible/#build-tools-and-net",
            "text": "Installation of .NET on  microsoft/windowsservercore  is not supported,\nbut microsoft provides the  microsoft/dotnet-framework  image.  TODO: Do we need to install multiple .NET versions? If not,\nthis image would be sufficient.  The build tools can be installed on the container following\nthe instruction on  this page in microsoft docs .\nUnfortunately, I haven't managed to finish it, due to some\nHCS errors. Perhaps it was related to insufficient disk\nspace (before running the Dockerfile I had 50GB free space).\nPerhaps there is some other way of installing build tools,\nwhich I haven't tested.",
            "title": "Build tools and .NET"
        },
        {
            "location": "/developer_guide/building/Dockerized_builder_using_ansible/#troubleshooting",
            "text": "When encountering weird errors in  docker build \n(the errors may come from HCS), it's probable that they're caused by:   Insufficient available RAM/swap on the host machine.  Insufficient RAM assigned to container.  Insufficient disk space on the host machine.  Insufficient disk space assigned to container.",
            "title": "Troubleshooting"
        },
        {
            "location": "/style_guides/C/",
            "text": "We try to maintain the same coding style as the rest of vRouter wherever we can, but still use conventions used by Windows Driver Kit wherever applicable (regarding variable names, P convention instead of * for specifying pointers to native Windows structures).\n\n\nBelow every rule, there is an example illustrating it with a code sample.\n\n\nGeneral\n\n\nStyling\n\n\n\n\nUse spaces, not tabs.\n\n\nOne indentation level is 4 spaces\n\n\nEvery line should end with a newline character ('\\n')\n\n\nNewlines commited into the remote repository should be Unix-like (newline character), avoid Windows-like newlines (carriage return; newline)\n\n\nAvoid magic numbers, unless there is a very good reason.\n\n\nUse define directives instead.\n\n\nStatements with blocks (if, while, for, do...) should have the opening bracket in the same line\n\n\nStatements with only one line instead of a whole block can skip brackets if it improves readability\n\n\nStatements if/else should not skip brackets unless it can be done for both if, else and all eventual else ifs\n\n\n\n\nif (condition)\n    do_something();\nelse\n    do_nothing();\n\n\nif (condition) {\n    do_something();\n} else {\n    i+= 1;\n    do_nothing();\n}\n\n\ndo {\n    ASSERT(FALSE);\n    nobody_uses_this_feature();\n} while(condition);\n\n\n\n\n\n\nIf, for, while and similar statements should not be too long. This means, for example creating variables for parts of statement being checked\n\n\n\n\nBOOLEAN usable = (value >= MIN_VALUE && value <= MAX_VALUE);\nBOOLEAN safe = (state == STABLE);\nif (usable && safe)\n    do_something();\n\n\n\n\nFiles\n\n\n\n\nFiles in 'windows' directory are free to modify and do not have to be platform portable (they have to be Windows-compatible)\n\n\nOther files need to be platform independant. This may be done in #ifdef manner, but more elegant solutions are preferable\n\n\nFor example callbacks\n\n\nFunction names should be:\nvr_filename.c or vr_filename.h\n** Please note vrouter_mod.c is an exception to this\n\n\nFiles should be in directory:\n\n windows for Windows source files (.c extension)\n\n include for header files (.h extension)\n*\n dp-core for multiplatform source files (we don't forsee creating any)\n\nFor header files, use guards to make sure there is no problem if they are included two or more times.\n\n\n\n\n#ifndef __VR_DEFS_H__\n#define __VR_DEFS_H__\n// Some code\n#endif\n\n\n\n\n\n\nUse #ifdef, not #pragma once for guards\n\n\n\n\nNaming\n\n\nFunctions\n\n\n\n\nName functions in snake case, names starting with vr_ or win_. Please note functions in vrouter_mod.c ATM don't follow this rule because of SxLibrary requirements. This will be changed when we get rid of it.\nvr_reinject_packet\n\n\nvr_ variant should be used for multiplatform functions\n\n\nwin_ variant should be used for Windows-specific functions.\n\n\nWhen defining function, place the type in one line and the rest of it in another line.\n\n\n\n\nunsigned int\nvr_reinject_packet(struct vr_packet *pkt, struct vr_forwarding_md *fmd)\n\n\n\n\n\n\nWhen declaring functions, use the extern keyword and write everything in one line.\n\n\n\n\nextern unsigned int vr_some_function();\n\n\n\n\n\n\nIt is preferential but not required to declare which parameters of a function are constant.\n\n\n\n\nint\nvr_function(const char* address)\n\n\n\n\nVariables\n\n\n\n\nWe avoid constant literal variables. Instead, one should avoid magic numbers using #define directive. Const structs are OK.\n\n\n\n\n#define MAX_SIZE 32\n\n\n\n\n\n\nGlobal variables can be used whenever necessary, especially when the function being implemented will be called by some pre-existing dp-core code without supplying required arguments. However, it is preferential to avoid them. Static variables are lesser evil. Please check if a global variable can be replaced with a static one\n\n\nVariables should be named using snake case.\n\n\n\n\nLARGE_INTEGER current_gmt_time;\n\n\n\n\n\n\nIt is preferential but not required to declare constant variables as such\n\n\n\n\nconst unsigned int num_of_tries = input + 5;\n\n\n\n\n\n\nIf a value is known to be always positive, one should use unsigned variable. Same for bitfields.\n\n\n\n\nunsigned int i = 5;\n\n\n\n\n\n\nVariables should be initialized before reading them.\n\n\n\n\nTypes\n\n\n\n\nExisting types should be used as-is\n\n\n\n\nPNET_BUFFER_LIST nbl;\n\n\n\n\n\n\nNew types and types declared by us should use snake case and begin with vr_.\n\n\n\n\nstruct vr_struct {};\n\n\n\n\n\n\nDo not typedef function, use struct as a part of the name\n\n\n\n\nstruct vr_router* router = vrouter_get(0);\n\n\n\n\nComments\n\n\n\n\nBoth block and line comments are allowed\n\n\n\n\nint i = pointer->field; // Pointer cannot be null\n\n/* TODO: Fix this */\n\n\n\n\n\n\nNon-obvious logic should be commented\n\n\nDo not leave commented out code unless there is a very good reason.\n\n\nPlatform-specific code\n\n\nUse #ifdefs to specify code that should be compiled on only selected platforms\n\n\n\n\n#ifdef __KERNEL__\n\n\n\n\n\n\nPrefer #ifdef to #if defined unless more specific statement checking if required.\n\n\n\n\n#if defined(_WINDOWS) || defined(__FreeBSD__)\n\n\n\n\n\n\nDo not use compiler or linker specific features in code if they would break compatibility with other tools. For example, most #pragma statements.\n\n\n\n\n#ifdef _WINDOWS\n#pragma warning(disable : 4018) // Disable warning about signed/unsigned mismatch\n#endif\n\n\n\n\n\n\nTry not to modify existing dp-core code if possible, otherwise modify it:\n\n\nPreferential: Creating additional callbacks (can be NULL or empty functions on Linux/FreeBSD)\n\n\n\n\nUsing #ifdefs\n\n\n\n\nTry not to use os, compiler or linker specific features if possible\n\n\nIf there is already some code implemented using them, consider reimplementing a native Linux function using Windows libraries. This function should only be compiled on Windows as Linux-like systems will provide their own implementation. Either of these two options will work\n\n\nWrite it in a file that will only be included on Windows\n\n\n\n\n#ifdef the implementation\nIf the body of a function will be completely different on Linux and Windows, write one function header and footer and #ifdef the rest of the body\nvoid print(const char* a)\n{\n#ifdef _WINDOWS\nDbgPrint(a);\n#else\nprintf(a);\n#endif\n}\n\n\n\n\n\n\nWindows-specific code should be properely ASSERTed. Use this function or ASSERTMSG to check your assumptions\n\n\n\n\nOther points\n\n\n\n\nIf a possible data-race condition arises, find the smallest critical section and wrap it into a mutex, semaphore or a RW lock.\n\n\nFunctions should return:\n\n In Windows-specific code: NDIS_STATUS and all effects via pointers unless the function cannot fail\n\n In multiplatform code: regular return value if functions succeeds and -errno if the function fails",
            "title": "C"
        },
        {
            "location": "/style_guides/C/#general",
            "text": "",
            "title": "General"
        },
        {
            "location": "/style_guides/C/#styling",
            "text": "Use spaces, not tabs.  One indentation level is 4 spaces  Every line should end with a newline character ('\\n')  Newlines commited into the remote repository should be Unix-like (newline character), avoid Windows-like newlines (carriage return; newline)  Avoid magic numbers, unless there is a very good reason.  Use define directives instead.  Statements with blocks (if, while, for, do...) should have the opening bracket in the same line  Statements with only one line instead of a whole block can skip brackets if it improves readability  Statements if/else should not skip brackets unless it can be done for both if, else and all eventual else ifs   if (condition)\n    do_something();\nelse\n    do_nothing();\n\n\nif (condition) {\n    do_something();\n} else {\n    i+= 1;\n    do_nothing();\n}\n\n\ndo {\n    ASSERT(FALSE);\n    nobody_uses_this_feature();\n} while(condition);   If, for, while and similar statements should not be too long. This means, for example creating variables for parts of statement being checked   BOOLEAN usable = (value >= MIN_VALUE && value <= MAX_VALUE);\nBOOLEAN safe = (state == STABLE);\nif (usable && safe)\n    do_something();",
            "title": "Styling"
        },
        {
            "location": "/style_guides/C/#files",
            "text": "Files in 'windows' directory are free to modify and do not have to be platform portable (they have to be Windows-compatible)  Other files need to be platform independant. This may be done in #ifdef manner, but more elegant solutions are preferable  For example callbacks  Function names should be:\nvr_filename.c or vr_filename.h\n** Please note vrouter_mod.c is an exception to this  Files should be in directory:  windows for Windows source files (.c extension)  include for header files (.h extension)\n*  dp-core for multiplatform source files (we don't forsee creating any) For header files, use guards to make sure there is no problem if they are included two or more times.   #ifndef __VR_DEFS_H__\n#define __VR_DEFS_H__\n// Some code\n#endif   Use #ifdef, not #pragma once for guards",
            "title": "Files"
        },
        {
            "location": "/style_guides/C/#naming",
            "text": "",
            "title": "Naming"
        },
        {
            "location": "/style_guides/C/#functions",
            "text": "Name functions in snake case, names starting with vr_ or win_. Please note functions in vrouter_mod.c ATM don't follow this rule because of SxLibrary requirements. This will be changed when we get rid of it.\nvr_reinject_packet  vr_ variant should be used for multiplatform functions  win_ variant should be used for Windows-specific functions.  When defining function, place the type in one line and the rest of it in another line.   unsigned int\nvr_reinject_packet(struct vr_packet *pkt, struct vr_forwarding_md *fmd)   When declaring functions, use the extern keyword and write everything in one line.   extern unsigned int vr_some_function();   It is preferential but not required to declare which parameters of a function are constant.   int\nvr_function(const char* address)",
            "title": "Functions"
        },
        {
            "location": "/style_guides/C/#variables",
            "text": "We avoid constant literal variables. Instead, one should avoid magic numbers using #define directive. Const structs are OK.   #define MAX_SIZE 32   Global variables can be used whenever necessary, especially when the function being implemented will be called by some pre-existing dp-core code without supplying required arguments. However, it is preferential to avoid them. Static variables are lesser evil. Please check if a global variable can be replaced with a static one  Variables should be named using snake case.   LARGE_INTEGER current_gmt_time;   It is preferential but not required to declare constant variables as such   const unsigned int num_of_tries = input + 5;   If a value is known to be always positive, one should use unsigned variable. Same for bitfields.   unsigned int i = 5;   Variables should be initialized before reading them.",
            "title": "Variables"
        },
        {
            "location": "/style_guides/C/#types",
            "text": "Existing types should be used as-is   PNET_BUFFER_LIST nbl;   New types and types declared by us should use snake case and begin with vr_.   struct vr_struct {};   Do not typedef function, use struct as a part of the name   struct vr_router* router = vrouter_get(0);",
            "title": "Types"
        },
        {
            "location": "/style_guides/C/#comments",
            "text": "Both block and line comments are allowed   int i = pointer->field; // Pointer cannot be null\n\n/* TODO: Fix this */   Non-obvious logic should be commented  Do not leave commented out code unless there is a very good reason.  Platform-specific code  Use #ifdefs to specify code that should be compiled on only selected platforms   #ifdef __KERNEL__   Prefer #ifdef to #if defined unless more specific statement checking if required.   #if defined(_WINDOWS) || defined(__FreeBSD__)   Do not use compiler or linker specific features in code if they would break compatibility with other tools. For example, most #pragma statements.   #ifdef _WINDOWS\n#pragma warning(disable : 4018) // Disable warning about signed/unsigned mismatch\n#endif   Try not to modify existing dp-core code if possible, otherwise modify it:  Preferential: Creating additional callbacks (can be NULL or empty functions on Linux/FreeBSD)",
            "title": "Comments"
        },
        {
            "location": "/style_guides/C/#using-ifdefs",
            "text": "Try not to use os, compiler or linker specific features if possible  If there is already some code implemented using them, consider reimplementing a native Linux function using Windows libraries. This function should only be compiled on Windows as Linux-like systems will provide their own implementation. Either of these two options will work  Write it in a file that will only be included on Windows   #ifdef the implementation\nIf the body of a function will be completely different on Linux and Windows, write one function header and footer and #ifdef the rest of the body\nvoid print(const char* a)\n{\n#ifdef _WINDOWS\nDbgPrint(a);\n#else\nprintf(a);\n#endif\n}   Windows-specific code should be properely ASSERTed. Use this function or ASSERTMSG to check your assumptions",
            "title": "Using #ifdefs"
        },
        {
            "location": "/style_guides/C/#other-points",
            "text": "If a possible data-race condition arises, find the smallest critical section and wrap it into a mutex, semaphore or a RW lock.  Functions should return:  In Windows-specific code: NDIS_STATUS and all effects via pointers unless the function cannot fail  In multiplatform code: regular return value if functions succeeds and -errno if the function fails",
            "title": "Other points"
        },
        {
            "location": "/style_guides/Cpp/",
            "text": "We aim to use a subset of all C++ features. This includes most features present in C++ up to C++11.\n\n\nGeneral\n\n\nPlatform-specific code\n\n\n\n\nUse #ifdef to differentiate Windows and non-Windows code\n\n\nTry to implement Windows-specific code on the lowest possible abstraction layer so that the higher ones can be platform agnostic.\n\n\nWhen providing alternate body of a function, use one function header/signature but two implementations in its body, encased in #ifdef guards.\n\n\n\n\nPractices\n\n\n\n\nUse class declarations in header files if the definition is not necessary.\n\n\n\n\nclass BgpAttr;\n\n\n\n\n\n\nIn header files, use #ifdef guards to prevent any issues arising from including the same header twice\n\n\n\n\n#ifndef ctrlplane_ksync_sock_h\n#define ctrlplane_ksync_sock_h\n// Some code\n#endif\nUse of many for-each variants instead of iterating over an index when accessing an array\nfor(auto &element : array) {\n  //do something...\n}\nauto itr = strvec.begin();\nwhile(itr != strvec.end()) {\n  //do something...\n  ++itr;\n}\n\n\n\n\nStyle\n\n\nFiles\n\n\n\n\nUse .cc files for C++ source code\n\n\nUse .h files for C++ header code\n\n\n\n\nNaming\n\n\nFiles\n\n\n\n\nFiles should be named in snake case.\n\n\n\n\niroute_aggregator.h\nClasses\nClasses should be named in camel case with the first letter capital\nclass IRouteAggregator {\n};\n\n\n\n\nFunctions/Methods\n\n\n\n\nMethods and functions should be named in upper camel case\n\n\n\n\nclass IRouteAggregator {\n    void Initialize();\n};\n\n\n\n\nVariables/Fields\n\n\n\n\nVariables and fields should be named according to the snake case convention\n** Note: Private fields often have a single underscore appended, as this makes creating a getter/setter more intuitive\n\n\n\n\nDesign\n\n\nParadigm\n\n\n\n\nAgent is designed with traditional object-oriented model of C++ application, therefore we should try to maintain that style.\n\n\n\n\nAgent does not use exceptions, instead relying on old-school return code error handling.\nint func()\n{\n    if (error)\n        return -ENOMEM;\n}\n\n\n\n\n\n\nAgent does use virtual and abstract (pure virtual) classes.\n\n\n\n\nclass Class {\npublic:\nvirtual void Func() = 0;\nvirtual void Func2();\nvoid Func3();\nprivate:\n};\n\n\n\n\n\n\nAgent uses proper visibility settings, ie. uses public, private and protected specifiers in class definitions.\n\n\nTemplating is used and encouraged.",
            "title": "Cpp"
        },
        {
            "location": "/style_guides/Cpp/#general",
            "text": "",
            "title": "General"
        },
        {
            "location": "/style_guides/Cpp/#platform-specific-code",
            "text": "Use #ifdef to differentiate Windows and non-Windows code  Try to implement Windows-specific code on the lowest possible abstraction layer so that the higher ones can be platform agnostic.  When providing alternate body of a function, use one function header/signature but two implementations in its body, encased in #ifdef guards.",
            "title": "Platform-specific code"
        },
        {
            "location": "/style_guides/Cpp/#practices",
            "text": "Use class declarations in header files if the definition is not necessary.   class BgpAttr;   In header files, use #ifdef guards to prevent any issues arising from including the same header twice   #ifndef ctrlplane_ksync_sock_h\n#define ctrlplane_ksync_sock_h\n// Some code\n#endif\nUse of many for-each variants instead of iterating over an index when accessing an array\nfor(auto &element : array) {\n  //do something...\n}\nauto itr = strvec.begin();\nwhile(itr != strvec.end()) {\n  //do something...\n  ++itr;\n}",
            "title": "Practices"
        },
        {
            "location": "/style_guides/Cpp/#style",
            "text": "",
            "title": "Style"
        },
        {
            "location": "/style_guides/Cpp/#files",
            "text": "Use .cc files for C++ source code  Use .h files for C++ header code",
            "title": "Files"
        },
        {
            "location": "/style_guides/Cpp/#naming",
            "text": "",
            "title": "Naming"
        },
        {
            "location": "/style_guides/Cpp/#files_1",
            "text": "Files should be named in snake case.   iroute_aggregator.h\nClasses\nClasses should be named in camel case with the first letter capital\nclass IRouteAggregator {\n};",
            "title": "Files"
        },
        {
            "location": "/style_guides/Cpp/#functionsmethods",
            "text": "Methods and functions should be named in upper camel case   class IRouteAggregator {\n    void Initialize();\n};",
            "title": "Functions/Methods"
        },
        {
            "location": "/style_guides/Cpp/#variablesfields",
            "text": "Variables and fields should be named according to the snake case convention\n** Note: Private fields often have a single underscore appended, as this makes creating a getter/setter more intuitive",
            "title": "Variables/Fields"
        },
        {
            "location": "/style_guides/Cpp/#design",
            "text": "",
            "title": "Design"
        },
        {
            "location": "/style_guides/Cpp/#paradigm",
            "text": "Agent is designed with traditional object-oriented model of C++ application, therefore we should try to maintain that style.   Agent does not use exceptions, instead relying on old-school return code error handling.\nint func()\n{\n    if (error)\n        return -ENOMEM;\n}   Agent does use virtual and abstract (pure virtual) classes.   class Class {\npublic:\nvirtual void Func() = 0;\nvirtual void Func2();\nvoid Func3();\nprivate:\n};   Agent uses proper visibility settings, ie. uses public, private and protected specifiers in class definitions.  Templating is used and encouraged.",
            "title": "Paradigm"
        },
        {
            "location": "/style_guides/Go/",
            "text": "Since docker driver written in Go is the only module of OpenContrail we've written completely by ourselves, we can introduce the best programming practices here, without regard for compatibility with legacy code.\n\n\nFor issues not discussed here, look at Official Code Review Comments.\n\n\nGeneral\n\n\nCoding style\n\n\n\n\nAvoid nesting if possible\n\n\nTry to exit from the function early in a case of an error\n\n\nUse tabs for indentations.\n\n\nOne tab is one indentation level.\n\n\nCode should be as compliant with gometalinter.\n\n\nIf a line would be longer than 100 characters (cound tab as 4 spaces for this), divide it into a few lines, so every line is shorter than said length.\n\n\n\n\nErrors\n\n\n\n\nHandle errors as soon as possible\n\n\nFunctions that are not sure to be successful should return error as one of returned values\n\n\n\n\nfunc SomeFunc(param string) (string, error) {\n\n\n\n\nOther guidelines\n\n\n\n\nTry to use libraries to do required functionality, instead of calling PowerShell commands or otherwise using external features if possible\n\n\nOften it's not possible\n\n\nUse log module to provide logging capability\n\n\nRemember to use different message levels correctly, ie. error for errors, info for regular info, debug for info which should usually be hidden, etc.\n\n\n\n\nlog.Infoln(\"Deleting HNS network\", hnsID)\n\n\n\n\nDesign\n\n\nModules\n\n\n\n\nKeep modules independent if possible\n\n\nOtherwise, make the dependency explicit\n\n\nDependencies can often be avoided by using interfaces\n\n\nWhen importing not inbuilt modules (eg. from github), keep a copy of them in vendor directory. Use govendor to upkeep it.\n\n\n\n\nFunctions\n\n\n\n\nFunctions should only accept as arguments what they really need, ie. io.Writer instead of *os.File\n\n\nDependencies can be avoided by using interfaces\n\n\nAvoid functions concurrent by default. By exposing synchronous API one can easily choose how to call the function, the other way around doesn't work.\n\n\nUse chans to communicate with goroutines\n\n\nUnexported functions should be named in camel case with first letter lowercase\n\n\nFunctions should be named in camel case with first letter capital for exported functions\n\n\n\n\nfunc CreateHNSNetwork(configuration *hcsshim.HNSNetwork) (string, error) {\n\n\n\n\nTesting\n\n\n\n\nAll features should be tested if possible\n\n\nFeatures implemented in file.go should be tested in file_test.go\n\n\nUsed frameworks should be ginkgo and gomega",
            "title": "Go"
        },
        {
            "location": "/style_guides/Go/#general",
            "text": "",
            "title": "General"
        },
        {
            "location": "/style_guides/Go/#coding-style",
            "text": "Avoid nesting if possible  Try to exit from the function early in a case of an error  Use tabs for indentations.  One tab is one indentation level.  Code should be as compliant with gometalinter.  If a line would be longer than 100 characters (cound tab as 4 spaces for this), divide it into a few lines, so every line is shorter than said length.",
            "title": "Coding style"
        },
        {
            "location": "/style_guides/Go/#errors",
            "text": "Handle errors as soon as possible  Functions that are not sure to be successful should return error as one of returned values   func SomeFunc(param string) (string, error) {",
            "title": "Errors"
        },
        {
            "location": "/style_guides/Go/#other-guidelines",
            "text": "Try to use libraries to do required functionality, instead of calling PowerShell commands or otherwise using external features if possible  Often it's not possible  Use log module to provide logging capability  Remember to use different message levels correctly, ie. error for errors, info for regular info, debug for info which should usually be hidden, etc.   log.Infoln(\"Deleting HNS network\", hnsID)",
            "title": "Other guidelines"
        },
        {
            "location": "/style_guides/Go/#design",
            "text": "",
            "title": "Design"
        },
        {
            "location": "/style_guides/Go/#modules",
            "text": "Keep modules independent if possible  Otherwise, make the dependency explicit  Dependencies can often be avoided by using interfaces  When importing not inbuilt modules (eg. from github), keep a copy of them in vendor directory. Use govendor to upkeep it.",
            "title": "Modules"
        },
        {
            "location": "/style_guides/Go/#functions",
            "text": "Functions should only accept as arguments what they really need, ie. io.Writer instead of *os.File  Dependencies can be avoided by using interfaces  Avoid functions concurrent by default. By exposing synchronous API one can easily choose how to call the function, the other way around doesn't work.  Use chans to communicate with goroutines  Unexported functions should be named in camel case with first letter lowercase  Functions should be named in camel case with first letter capital for exported functions   func CreateHNSNetwork(configuration *hcsshim.HNSNetwork) (string, error) {",
            "title": "Functions"
        },
        {
            "location": "/style_guides/Go/#testing",
            "text": "All features should be tested if possible  Features implemented in file.go should be tested in file_test.go  Used frameworks should be ginkgo and gomega",
            "title": "Testing"
        },
        {
            "location": "/updating_documentation/How_to_update_this_documentation/",
            "text": "How to update this documentation\n\n\nHow does it work\n\n\nDocumentation is stored on master branch of Juniper/contrail-windows-docs repository. It is stored in Markdown (.md) format. Documentation is served as HTML on github.io. HTML pages are generated by MkDocs tool. HTML pages need to be redeployed manually after modification.\n\n\nDocumentation update procedure (procedure for developer)\n\n\n\n\nOpen a pull request to master branch in repository Juniper/contrail-windows-docs with your changes.\n\n\nOnce PR is accepted, an administrator is going to deploy new modifications to gh-pages branch.\n\n\n\n\nHow to preview modifications (procedure for developer)\n\n\n\n\nInstall MkDocs (see below).\n\n\nApply required modifications to the documentation.\n\n\nInvoke \nmkdocs serve\n in main repository directory. It's going to start local HTTP server with documentation preview. Follow instructions displayed by mkdocs to see the outcome.\n\n\n\n\nHow to install MkDocs (procedure for administrator and developer)\n\n\nMkDocs requires Python (both Python 2 and Python 3 are supported) and PIP. Follow instructions on \nhttp://www.mkdocs.org/#installation\n. Basically \npip install mkdocs\n should work. It may also be useful to use virtualenv to keep mkdocs and its dependencies in one isolated place.\n\n\nHow to deploy modifications (procedure for administrator)\n\n\nAfter master branch of Juniper/contrail-windows-docs repository is updated, github.io pages need to be redeployed manually. To do this, follow these steps:\n\n\n\n\nInstall MkDocs.\n\n\nCheckout master branch of repository Juniper/contrail-windows-docs.\n\n\nInvoke \nmkdocs gh-deploy\n in main repository directory and follow displayed instructions. Additional details are described in \nhttp://www.mkdocs.org/user-guide/deploying-your-docs/\n.",
            "title": "How to update this documentation"
        },
        {
            "location": "/updating_documentation/How_to_update_this_documentation/#how-to-update-this-documentation",
            "text": "",
            "title": "How to update this documentation"
        },
        {
            "location": "/updating_documentation/How_to_update_this_documentation/#how-does-it-work",
            "text": "Documentation is stored on master branch of Juniper/contrail-windows-docs repository. It is stored in Markdown (.md) format. Documentation is served as HTML on github.io. HTML pages are generated by MkDocs tool. HTML pages need to be redeployed manually after modification.",
            "title": "How does it work"
        },
        {
            "location": "/updating_documentation/How_to_update_this_documentation/#documentation-update-procedure-procedure-for-developer",
            "text": "Open a pull request to master branch in repository Juniper/contrail-windows-docs with your changes.  Once PR is accepted, an administrator is going to deploy new modifications to gh-pages branch.",
            "title": "Documentation update procedure (procedure for developer)"
        },
        {
            "location": "/updating_documentation/How_to_update_this_documentation/#how-to-preview-modifications-procedure-for-developer",
            "text": "Install MkDocs (see below).  Apply required modifications to the documentation.  Invoke  mkdocs serve  in main repository directory. It's going to start local HTTP server with documentation preview. Follow instructions displayed by mkdocs to see the outcome.",
            "title": "How to preview modifications (procedure for developer)"
        },
        {
            "location": "/updating_documentation/How_to_update_this_documentation/#how-to-install-mkdocs-procedure-for-administrator-and-developer",
            "text": "MkDocs requires Python (both Python 2 and Python 3 are supported) and PIP. Follow instructions on  http://www.mkdocs.org/#installation . Basically  pip install mkdocs  should work. It may also be useful to use virtualenv to keep mkdocs and its dependencies in one isolated place.",
            "title": "How to install MkDocs (procedure for administrator and developer)"
        },
        {
            "location": "/updating_documentation/How_to_update_this_documentation/#how-to-deploy-modifications-procedure-for-administrator",
            "text": "After master branch of Juniper/contrail-windows-docs repository is updated, github.io pages need to be redeployed manually. To do this, follow these steps:   Install MkDocs.  Checkout master branch of repository Juniper/contrail-windows-docs.  Invoke  mkdocs gh-deploy  in main repository directory and follow displayed instructions. Additional details are described in  http://www.mkdocs.org/user-guide/deploying-your-docs/ .",
            "title": "How to deploy modifications (procedure for administrator)"
        },
        {
            "location": "/windows_compute/Communication_Agent_Extension/",
            "text": "There are three ways in which vRouter Agent exchanges information with the Forwarding Extension, which mimics their Linux behaviour.\n\n\nKsync\n\n\nThis communication channel is used for inserting forwarding rules into the Forwarding Extension, like routes and next hops.\n\n\nOn Linux, Netlink sockets are used for this. Equivalent Windows mechanism is a Named Pipe.\n\n\nOnly vRouter Agent and other userspace programs can initialize the communiation. Howerver, different programs (for example, Agent and utils) may talk via ksync at the same time, so process separation (session layer) is required.\n\n\nThis communication is performed over a binary protocol called Sandesh (the same one which is used by Contrail Analytics Nodes).\n\n\nFlow\n\n\nAll flows are inserted into the Forwarding Extension using shared memory mechanism. Shared memory is allocated inside Forwarding Extension, and is written to by Agent. Only Agent may allocate flows inside the shared memory. Forwarding Extension may modify the shared memory contents, but it never directly communicates with vRouter Agent using it or creates new flows - it mostly updates flow statistics.\n\n\nOnly Agent and \"flow\" util need access to shared memory from userspace.\n\n\nSince kernel memory is mapped into userspace, so the team ensured that the implementation is secure.\n\n\npkt0\n\n\nThis channel is asynchronous - both vRouter Agent and Forwarding Extension can send packets through it at arbitrary times.\n\n\nWhen a \"new\" packet arrives at Forwarding Extension (for example, ARP or DHCP request), it will transfer it using pkt0 to vRouter Agent. vRouter Agent will then analyze the packet (possibly sending it to Contrail Controller for even more analysis), and insert ksync rules or flows into the Forwarding Extension. Then, it re-injects the packet into the Forwarding Extension. \n\n\nPkt0 is implemented on Linux using a traditional networking interface, of AF_PACKET family. On Windows, this is done using a named pipe. The reason for this is that Windows implementation of Berkeley sockets does not allow any manipulation of any layer below IP.\n\n\nNamed pipe server is created by the Forwarding Extension.\n\n\nSandesh\n\n\nSandesh is a binary protocol based on Apache Thrift. It's a set of header files to be included in projects that use it, but also a code generation tool. Sandesh uses own Interface Definition Language to generate code in many different languages, like Java, C, Python and Golang. Generated code consists of definitions of data structures and getter/setter functions.",
            "title": "Communication Agent Extension"
        },
        {
            "location": "/windows_compute/Communication_Agent_Extension/#ksync",
            "text": "This communication channel is used for inserting forwarding rules into the Forwarding Extension, like routes and next hops.  On Linux, Netlink sockets are used for this. Equivalent Windows mechanism is a Named Pipe.  Only vRouter Agent and other userspace programs can initialize the communiation. Howerver, different programs (for example, Agent and utils) may talk via ksync at the same time, so process separation (session layer) is required.  This communication is performed over a binary protocol called Sandesh (the same one which is used by Contrail Analytics Nodes).",
            "title": "Ksync"
        },
        {
            "location": "/windows_compute/Communication_Agent_Extension/#flow",
            "text": "All flows are inserted into the Forwarding Extension using shared memory mechanism. Shared memory is allocated inside Forwarding Extension, and is written to by Agent. Only Agent may allocate flows inside the shared memory. Forwarding Extension may modify the shared memory contents, but it never directly communicates with vRouter Agent using it or creates new flows - it mostly updates flow statistics.  Only Agent and \"flow\" util need access to shared memory from userspace.  Since kernel memory is mapped into userspace, so the team ensured that the implementation is secure.",
            "title": "Flow"
        },
        {
            "location": "/windows_compute/Communication_Agent_Extension/#pkt0",
            "text": "This channel is asynchronous - both vRouter Agent and Forwarding Extension can send packets through it at arbitrary times.  When a \"new\" packet arrives at Forwarding Extension (for example, ARP or DHCP request), it will transfer it using pkt0 to vRouter Agent. vRouter Agent will then analyze the packet (possibly sending it to Contrail Controller for even more analysis), and insert ksync rules or flows into the Forwarding Extension. Then, it re-injects the packet into the Forwarding Extension.   Pkt0 is implemented on Linux using a traditional networking interface, of AF_PACKET family. On Windows, this is done using a named pipe. The reason for this is that Windows implementation of Berkeley sockets does not allow any manipulation of any layer below IP.  Named pipe server is created by the Forwarding Extension.",
            "title": "pkt0"
        },
        {
            "location": "/windows_compute/Communication_Agent_Extension/#sandesh",
            "text": "Sandesh is a binary protocol based on Apache Thrift. It's a set of header files to be included in projects that use it, but also a code generation tool. Sandesh uses own Interface Definition Language to generate code in many different languages, like Java, C, Python and Golang. Generated code consists of definitions of data structures and getter/setter functions.",
            "title": "Sandesh"
        },
        {
            "location": "/windows_compute/Container_creation_lifecycle/",
            "text": "Docker client tells docker daemon to run a container and attach it to a Docker network (that corresponds to a chunk of a Contrail subnet).\n\n\nDocker deamon delegates the network configuration of the container that is being created to the remote docker driver.\n\n\nDocker driver queries docker daemon about metadata associated with docker's network resource and receives Contrail tenant name and subnet CIDR.\n\n\nDocker driver performs a series of queries against Contrail Controller that create various Contrail resources, most notably: virtual-machine, virtual-machine-interface, instance-ip.\n\n\nDocker driver receives Instance IP, MAC and default gateway to configure the newly created container's interface with. It also receives UUID of virtual-machine-interface resource\n\n\nDocker driver knows all the information necessary to recreate HNS Network's name. It uses this name to identify which HNS network to attach the container to. Docker driver sends requests to HNS to configure endpoint with newly received IP, MAC and Default gateway.\n\n\nIn the background, HNS creates the network compartment for the container and configures its interface.\n\n\nThe moment the interface is created, the Forwarding Extension receives an event about new adapter being connected. \n\n\nForwarding Extension doesn't know what to do with it yet, so it stores it in a hash map, where the key is adapters FriendlyName. Then it waits, dropping all packets except the ones sent from native Hyper-V driver.\n\n\nMeanwhile, if container creation was successful, HNS returns ID of the endpoint to docker driver.\n\n\nDocker driver sends \"add port\" request to vRouter Agent, with all the necessary information to identify the port both in Contrail terms (UUID of virtual-machine-interface) as well as in Windows terms (using Endpoint ID, which is a part of FriendlyName).\n\n\nvRouter Agent communicates with Contrail Controller to let it know about newly added port.\n\n\nvRouter Agent inserts basic rules and flows into the Forwarding Extension. \n\n\nForwarding Extension uses the FriendlyName to determine which port seen in userspace corresponds to port waiting in Forwarding Extension's hash map.",
            "title": "Container creation lifecycle"
        },
        {
            "location": "/windows_compute/Docker_on_Windows/",
            "text": "Docker\n\n\nDocker is a popular tools for managing containers on Linux.\n\n\nSince Windows Server 2016, docker is the main tool used for managing Windows Containers.\n\n\nDocker client\n\n\nDocker command line tool, which communicates with Docker Daemon over a named pipe.\n\n\nDocker daemon\n\n\nA program that runs as a service. It exposes an API over a named pipe. It's responsible for managing containers, from parsing Dockerfiles and pulling layers to basic networking.\n\n\nDocker is cross-platform and is integrated into many different network orchestration systems. This is achieved thanks to its plugin architecture. One can implement all kinds of plugins for docker, for example for volume or network management. These plugins can either be integrated into docker's code directly, or can be implemented as Remote drivers. The advantage of Remote drivers is that one doesn't have to build the whole Docker if she wants to implement a driver. Remote drivers on Windows can use tcp sockets or named pipes for communication. In either case, docker daemon will look for a \"spec file\" in a specific path: $Env:ProgramData\\docker\\plugins. The name of the spec file must be the same as driver's name. The file itself contains a protocol and address on which docker daemon will try to initiate communication.\n\n\nSince docker is written in Go, Microsoft engineers had to expose an API for managing Windows Containers written in this language. \n\n\nHost compute service (HCS) & host network service (HNS)\n\n\nGolang wrapper for HCS and HNS is implemented in a public hcsshim repository: www.github.com/Microsoft/hcsshim. HCS and HNS are Windows Services responsible for light container virtualization as well as setting up virtual networking for them. They are implemented in some system dynamic libraries, which interact with the kernel directly. How it works isn't documented.\n\n\nHost compute service\n\n\nDeals with volumes, filesystem layers etc. It's related to HNS, but it's not inside scope of the project directly.\n\n\nHost network service\n\n\nHNS is a wrapper for syscalling functions in vmcompute.dll. Only one file in the whole hcsshim repository is used by HNS - 'hnsfuncs.go'.\n\n\nWindows Containers\n\n\nWindows Containers are a feature shipped with Windows Server 2016, Windows 10 and Windows Nano Server. These act similarly to lxc containers. On Windows, they are implemented using various namespaces, as well as network namespace equivalent (called network compartment).\n\n\nNetwork compartments are not documented, but vmcompute.dll contains some functions related to how they work.\nUnlike on Linux, Windows supports two types/levels of isolation for its containers:\n\n Windows Server containers, which work just like normal Linux containers - they all share the kernel\n\n Hyper-V containers. These are essentialy small VMs (running Nano Server), that run Windows Containers which then run the container we wanted. This additional level of virtualization is useful mostly for security reasons. It provides some pros and cons of both containers and VMs. To run a container in this mode, one needs to add \"--isolation-level=hyperv\" to \"docker run\" command.\n\n\nThere are no differences on how networking is implemented for both of these types of containers.\n\n\nThere are two base images for docker container creation:\n\n\n\n\nmicrosoft/windowsservercore which is headless version of normal Windows Server Core\n\n\nmicrosoft/nanoserver which is very lightweight, stripped of most functionality version of Windows Server Core",
            "title": "Docker"
        },
        {
            "location": "/windows_compute/Docker_on_Windows/#docker",
            "text": "Docker is a popular tools for managing containers on Linux.  Since Windows Server 2016, docker is the main tool used for managing Windows Containers.",
            "title": "Docker"
        },
        {
            "location": "/windows_compute/Docker_on_Windows/#docker-client",
            "text": "Docker command line tool, which communicates with Docker Daemon over a named pipe.",
            "title": "Docker client"
        },
        {
            "location": "/windows_compute/Docker_on_Windows/#docker-daemon",
            "text": "A program that runs as a service. It exposes an API over a named pipe. It's responsible for managing containers, from parsing Dockerfiles and pulling layers to basic networking.  Docker is cross-platform and is integrated into many different network orchestration systems. This is achieved thanks to its plugin architecture. One can implement all kinds of plugins for docker, for example for volume or network management. These plugins can either be integrated into docker's code directly, or can be implemented as Remote drivers. The advantage of Remote drivers is that one doesn't have to build the whole Docker if she wants to implement a driver. Remote drivers on Windows can use tcp sockets or named pipes for communication. In either case, docker daemon will look for a \"spec file\" in a specific path: $Env:ProgramData\\docker\\plugins. The name of the spec file must be the same as driver's name. The file itself contains a protocol and address on which docker daemon will try to initiate communication.  Since docker is written in Go, Microsoft engineers had to expose an API for managing Windows Containers written in this language.",
            "title": "Docker daemon"
        },
        {
            "location": "/windows_compute/Docker_on_Windows/#host-compute-service-hcs-host-network-service-hns",
            "text": "Golang wrapper for HCS and HNS is implemented in a public hcsshim repository: www.github.com/Microsoft/hcsshim. HCS and HNS are Windows Services responsible for light container virtualization as well as setting up virtual networking for them. They are implemented in some system dynamic libraries, which interact with the kernel directly. How it works isn't documented.",
            "title": "Host compute service (HCS) &amp; host network service (HNS)"
        },
        {
            "location": "/windows_compute/Docker_on_Windows/#host-compute-service",
            "text": "Deals with volumes, filesystem layers etc. It's related to HNS, but it's not inside scope of the project directly.",
            "title": "Host compute service"
        },
        {
            "location": "/windows_compute/Docker_on_Windows/#host-network-service",
            "text": "HNS is a wrapper for syscalling functions in vmcompute.dll. Only one file in the whole hcsshim repository is used by HNS - 'hnsfuncs.go'.",
            "title": "Host network service"
        },
        {
            "location": "/windows_compute/Docker_on_Windows/#windows-containers",
            "text": "Windows Containers are a feature shipped with Windows Server 2016, Windows 10 and Windows Nano Server. These act similarly to lxc containers. On Windows, they are implemented using various namespaces, as well as network namespace equivalent (called network compartment).  Network compartments are not documented, but vmcompute.dll contains some functions related to how they work.\nUnlike on Linux, Windows supports two types/levels of isolation for its containers:  Windows Server containers, which work just like normal Linux containers - they all share the kernel  Hyper-V containers. These are essentialy small VMs (running Nano Server), that run Windows Containers which then run the container we wanted. This additional level of virtualization is useful mostly for security reasons. It provides some pros and cons of both containers and VMs. To run a container in this mode, one needs to add \"--isolation-level=hyperv\" to \"docker run\" command.  There are no differences on how networking is implemented for both of these types of containers.  There are two base images for docker container creation:   microsoft/windowsservercore which is headless version of normal Windows Server Core  microsoft/nanoserver which is very lightweight, stripped of most functionality version of Windows Server Core",
            "title": "Windows Containers"
        },
        {
            "location": "/windows_compute/Forwarding_extension/",
            "text": "On Linux, a special vRouter Kernel Module is enabled to perform the heavy-duty, high-performance datapath functionality of Contrail. The Forwarding Extension is a Windows equivalent. It's implemented as a forwarding extension of Window's Hyper-V Extensible Switch.\n\n\nNote: Even though the name \"forwarding extension\" refers to the type of extension of Hyper-V Switch, the team calls the equivalent of Linux kernel module as \"the Forwarding Extension\".\n\n\nDP-core is a cross platform module that is responsible for datapath logic. Even though its design is cross platform (DP-core exposes a set of function pointers, that need to be implemented differently on different operating systems, for example memory allocation, packet inspection procedures, timer functions etc.), its implementation uses many gcc-specific built ins, which require porting over to Windows.\n\n\nNote: In theory, kernel extension compiled with GCC might work on Windows, but Visual Studio compiler is recommended.\n\n\nThe Extension implements an NDIS (Network Driver Interface Specification) API. The NDIS API is event driven, and is realized in terms of callback functions.\n\n\nThere is two-way interaction between DP-core and NDIS:\n\n\n\n\nSince the Extension is event driven, whenever an event occurs, a specific NDIS callback is ran - for example, if a packet is received, or a new port is connected. In those cases, DP-core's functions will need to be used inside the callback to enact vRouter logic and reach a forwarding decision.\n\n\nHowever, DP-core sometimes needs additional information to reach those decisions. It uses the \"callbacks\" in form of aforementioned function pointers to OS-specific implementations of those functionalities.\n\n\n\n\nNote: In other words, there are two \"kinds\" of callbacks: \"NDIS callbacks\" and \"DP-core callbacks\". NDIS callbacks are a consequence of event-driven architecture of Hyper-V Extensions, while DP-core callbacks are actually just platform specific \"dependency injections\" or \"C interfaces\". \nThe team usually refers to those \"DP-core callbacks\" as just callbacks. NDIS callbacks are usually referred to as \"Extension/NDIS API implementation\".\n\n\nNote: There is a convenience library provided by Microsoft around the raw NDIS API. The library is referred to as SxBase, but it's just 4 source files. They can be found here: https://github.com/Microsoft/Windows-driver-samples/tree/master/network/ndis/extension/base. SxBase is used in the current implementation, but it will HAVE TO be replaced in the future, due to licensing issues.\n\n\nThe Forwarding Extension does not directly communicate with Contrail Controller. Instead, vRouter Agent is responsible for creating all the objects and flows inside the Extension.",
            "title": "Forwarding extension"
        },
        {
            "location": "/windows_compute/HyperV_extensible_switch/",
            "text": "Windows Server 2012 introduced Hyper-V Extensible Switch. It\u2019s a virtual switch that runs in OS running in Hyper-V\u2019s parent partition. It\u2019s mainly used for forwarding packets flowing in and out of child partitions (VMs and containers).\n\n\nThree types of switches can be instantiated:\n\n\n\n\nprivate - only interfaces connected to the vSwitch can communicate\n\n\ninternal - like private, but the host (hypervisor) is also connected\n\n\nexternal - like internal, but external network adapter is also connected. Usually, this is the physical adapter. Multiple external switches may exist at any given time.\n\n\n\n\nHyper-V Extensible Switch is \"Extensible\", which means it can be extended using third party extensions (plugins).\n\n\nMultiple extensions can be enabled at the same time. Hyper-V Switch's plugin architecture resembles a stack. The order in which ingress and egress packets will be processed by a specific extension depends on their position in the filter stack.\n\n\nThere are three types of extensions:\n\n\n\n\ncapture - which can inspect packets, and, for example, log them somewhere\n\n\nfilter - like capture, but has the ability to drop packets\n\n\nforwarding - like filter, but has the ability to forward and modify the packets.\n\n\n\n\nMultiple instances of capture and filter extensions can be enabled in arbitrary locations in the extensions stack, but only one forwarding extension can be enabled at a time. It must be located at the bottom of the stack as well, which means that it is the last to process ingress packets, but the first to process egress packets.",
            "title": "HyperV extensible switch"
        },
        {
            "location": "/windows_compute/Linux_Overview/",
            "text": "Contrail Controller\n\n\nContrail Controller is a logical component. In fact, it's a distributed system consisting of many nodes, most importantly:\n\n\n\n\nConfig nodes. These nodes expose a REST API used by various applications to configure Contrail resources. Contrail's web client communicates with it, and so does Docker Network Driver. Config information is eventually propagated to Control nodes.\n\n\nControl nodes, responsible for interacting with vRouter Agent via XMPP protocol. These interactions include inserting forwarding rules and flows and sending packets for further analysis.\n\n\nAnalytics nodes, which collect high volume information using Sandesh binary protocol.\n\n\n\n\nvRouter Agent mainly interacts with Control and Analytics nodes, while Docker network driver interacts with Config nodes. \n\n\nCompute Node\n\n\nCompute Node is a Contrail component. It's a hypervisor that is able to spawn VMs or containers. Every compute node must have an instance of vRouter Agent running.\n\n\nWindows Server 2016 and Nano Server are new versions of Microsoft's OS, that can act both as Hyper-V hypervisor as well as Windows Containers host.\n\n\nNano Server running as Compute Node is currently not supported, due to lacking the capability of installing Hyper-V networking extensions.\n\n\nvRouter Agent\n\n\nNote: The team sometimes refers to vRouter Agent simply as \"vRouter\", \"Agent\" or \"vRA\".\n\n\nvRouter Agent is a Contrail agent that runs in userspace on a compute node. It has many functions. Most importantly:\n\n\n\n\nit communicates with Contrail Controller via XMPP protocol. Controller will inject rules and flows into the agent so that it enacts it's routing policies and implements network virtualization,\nexposes an API for the hypervisor, that is used for registering newly created virtual machines or containers. This * is most notably used in Contrail-OpenStack integration, where Nova-Agent informs vRouter Agent whenever a new VM is spawned. On Windows, the API is exposed over a named pipe.\n\n\ncommunicates with the Forwarding Extension (three communication channels in total). Since vRouter Agent is a control plane component, it must inject all low level information like next hops, virtual interface information, routes and flows into the datapath component (the Forwarding Extension).\n\n\nsometimes forwards packets from Forwarding Extension to Contrail Controller\n\n\nsometimes injects packets sent from Contrail Controller into the Forwarding Extension",
            "title": "Contrail Controller"
        },
        {
            "location": "/windows_compute/Linux_Overview/#contrail-controller",
            "text": "Contrail Controller is a logical component. In fact, it's a distributed system consisting of many nodes, most importantly:   Config nodes. These nodes expose a REST API used by various applications to configure Contrail resources. Contrail's web client communicates with it, and so does Docker Network Driver. Config information is eventually propagated to Control nodes.  Control nodes, responsible for interacting with vRouter Agent via XMPP protocol. These interactions include inserting forwarding rules and flows and sending packets for further analysis.  Analytics nodes, which collect high volume information using Sandesh binary protocol.   vRouter Agent mainly interacts with Control and Analytics nodes, while Docker network driver interacts with Config nodes.",
            "title": "Contrail Controller"
        },
        {
            "location": "/windows_compute/Linux_Overview/#compute-node",
            "text": "Compute Node is a Contrail component. It's a hypervisor that is able to spawn VMs or containers. Every compute node must have an instance of vRouter Agent running.  Windows Server 2016 and Nano Server are new versions of Microsoft's OS, that can act both as Hyper-V hypervisor as well as Windows Containers host.  Nano Server running as Compute Node is currently not supported, due to lacking the capability of installing Hyper-V networking extensions.",
            "title": "Compute Node"
        },
        {
            "location": "/windows_compute/Linux_Overview/#vrouter-agent",
            "text": "Note: The team sometimes refers to vRouter Agent simply as \"vRouter\", \"Agent\" or \"vRA\".  vRouter Agent is a Contrail agent that runs in userspace on a compute node. It has many functions. Most importantly:   it communicates with Contrail Controller via XMPP protocol. Controller will inject rules and flows into the agent so that it enacts it's routing policies and implements network virtualization,\nexposes an API for the hypervisor, that is used for registering newly created virtual machines or containers. This * is most notably used in Contrail-OpenStack integration, where Nova-Agent informs vRouter Agent whenever a new VM is spawned. On Windows, the API is exposed over a named pipe.  communicates with the Forwarding Extension (three communication channels in total). Since vRouter Agent is a control plane component, it must inject all low level information like next hops, virtual interface information, routes and flows into the datapath component (the Forwarding Extension).  sometimes forwards packets from Forwarding Extension to Contrail Controller  sometimes injects packets sent from Contrail Controller into the Forwarding Extension",
            "title": "vRouter Agent"
        },
        {
            "location": "/windows_compute/Network_creation_lifecycle/",
            "text": "There is a slight discrepancy between Docker's and Contrail's networking model. Contrail can implement a logical, overlay network for containers. However, docker can only create a network locally, on the hypervisor.\n\n\nThis means that \"docker network create\" command needs to be ran on each hypervisor that will contain any container that could be connected to a specific network. In other words, \"local\" networks must be prepared on each host.\n\n\nFurthermore, Docker's \"network\" is actually equivalent to Contrail's \"subnet\". This means, that during docker network creation, specific Contrail subnet (using CIDR notation) must be specified as a parameter.\n\n\n\n\nDocker client tells docker daemon to create a docker network that will represent a chunk of a Contrail subnet. Tenant name, network name and subnet's CIDR are passed as parameters.\n\n\nDocker daemon creates a network resource in its own, local database, and then delegates handling of network configuration to the docker driver.\n\n\nDocker driver queries Contrail Controller whether specified tenant, network and subnet combination exists. It also asks for their details.\n\n\nContrail Controller returns subnet's default gateway address as well as subnet's UUID\n\n\nDocker driver calls HNS function to create a HNS network with subnet's CIDR and default gateway address. It also sets the HNS network's name as a concatenation of \"Contrail\" with tenant name, network name and subnet ID.\n\n\nDocker driver tells docker daemon to store tenant and network names in docker network's metadata. Docker daemon stores this information in its own, local database.",
            "title": "Network creation lifecycle"
        },
        {
            "location": "/windows_compute/Root_HNS_network/",
            "text": "HNS operates by using two virtual switches:\n\n\n\n\nan external vswitch, which is connected directly to physical adapter. This adapter is called \"vEthernet (HNSTransparent)\", and the switch is called \"Layered Etherenet0\" depending on which physicial adapter it's connected to. If there is physical NIC teaming, then its name contains all the physical adapters separated by a coma, like \"Layered Ethernet0,Ethernet1\"\n\n\nan internal vswitch, for the purpose of NATing. The adapter that connects to the host is named \"vEthernet (HNS Internal NIC)\", and the switch is called \"nat\".\n\n\n\n\nThose virtual switches are not created unless there is at least one HNS network using corresponding Mode: \"transparent\" or \"nat\". If the last network of corresponding Mode is removed, the vswitch is also removed. Creation/deletion of vswitch takes a couple seconds and disrupts network connectivity.\n\n\nThis dynamism of creating/deleting vswitches poses a problem, because we want vRouter Forwarding Extension to be persistent, no matter if there are many or no virtual networks. That's why, when Docker Driver initializes, it creates a \"dummy\" Root HNS Network, which makes HNS create an external vswitch \"Layered Ethernet*\". Forwarding Extension is then enabled for that vswitch.",
            "title": "Root HNS network"
        },
        {
            "location": "/windows_compute/Utility_tools/",
            "text": "A set of utility tools (sometimes referred to simply as \"Utils\") useful for manually injecting rules into the datapath or for introspect and debugging. They communicate directly with the Forwarding Extension. There are split into two categories:\n\n\nBasic utils\n\n\nThese are used for basic vRouter introspection, but also for manual insertion of own rules and objects into the Forwarding Extension.\n\n\n\n\nvif - used for showing and creating virtual interfaces\n\n\nnh - used for showing and creating next hops\n\n\nrt - used for showing and creating routes\n\n\nflow - used for showing flows\n\n\n\n\nThe fifth \"basic util\" is a test util. Since kernel drivers are hard to test without moving them into userspace, Juniper decided to implement a tool that simulates normal usage.\n\n\n\n\nvtest - runs playback tests against the Forwarding Extension\n\n\n\n\nExtended utils\n\n\nThese are mainly used for statistics and advanced debugging.\n\n\n\n\nvxlan\n\n\nvrmemstats\n\n\nvrfstats\n\n\nqosmap\n\n\nmpls\n\n\ndropstats\n\n\nmirror",
            "title": "Utility tools"
        },
        {
            "location": "/windows_compute/Utility_tools/#basic-utils",
            "text": "These are used for basic vRouter introspection, but also for manual insertion of own rules and objects into the Forwarding Extension.   vif - used for showing and creating virtual interfaces  nh - used for showing and creating next hops  rt - used for showing and creating routes  flow - used for showing flows   The fifth \"basic util\" is a test util. Since kernel drivers are hard to test without moving them into userspace, Juniper decided to implement a tool that simulates normal usage.   vtest - runs playback tests against the Forwarding Extension",
            "title": "Basic utils"
        },
        {
            "location": "/windows_compute/Utility_tools/#extended-utils",
            "text": "These are mainly used for statistics and advanced debugging.   vxlan  vrmemstats  vrfstats  qosmap  mpls  dropstats  mirror",
            "title": "Extended utils"
        },
        {
            "location": "/windows_compute/_Blueprint/",
            "text": "Rationale and Scope\n\n\nWindows Server 2016 comes with support for containers and docker. Pros and cons of using containers are well known. This also sets up Contrail for possible Hyper-V support in the future.\n\n\nThe scope is to port Compute node to Windows (Agent and vRouter) and integrate with Windows docker and Windows Containers.\n\n\nImplementors\n\n\nRajagopalan Sivaramakrishnan (raja@juniper.net)\nSagar Chitnis (sagarc@juniper.net)\nCodiLime dev team (windows-contrail@codilime.com)\n\n\nTarget Release\n\n\nFor release 1: 5.0\nFor release 2+: tbd\n\n\nUser-visible changes\n\n\nOn Linux, none.\nOn Windows, one can use Windows docker command line tools to spawn Windows containers and connect them to Contrail networks. (orchestration is not in scope of release 1)\nFor deployment, MSI installers are provided.\n\n\nInternal changes\n\n\n3 components are affected:\n\n\n\n\n\n\nWindows docker driver is added. It is roughly equivalent to Nova Agent, but runs as a Windows service and implements docker driver APIs. It communicates with config, Agent and HNS (Host Network Service - Windows container management service). Written in Golang.\n\n\n\n\n\n\nvRouter Agent. Parts of the codebase are not cross platform. Changes involve rewriting those and fixing related bugs.\n\n\n\n\n\n\nvRouter Forwarding Extension. Implements vRouter kernel module functionality in terms of a Hyper-V Forwarding Extension, which is basically a kernel mode \"plugin\" for Windows virtual switch.\n\n\n\n\n\n\nLinux communication channels between (2) and (3) are also ported using Named Pipes (for ksync and pkt0) and Windows shared memory (for flow).\n\n\nMore info is available under spec url.",
            "title": " Blueprint"
        },
        {
            "location": "/windows_compute/_Blueprint/#rationale-and-scope",
            "text": "Windows Server 2016 comes with support for containers and docker. Pros and cons of using containers are well known. This also sets up Contrail for possible Hyper-V support in the future.  The scope is to port Compute node to Windows (Agent and vRouter) and integrate with Windows docker and Windows Containers.",
            "title": "Rationale and Scope"
        },
        {
            "location": "/windows_compute/_Blueprint/#implementors",
            "text": "Rajagopalan Sivaramakrishnan (raja@juniper.net)\nSagar Chitnis (sagarc@juniper.net)\nCodiLime dev team (windows-contrail@codilime.com)",
            "title": "Implementors"
        },
        {
            "location": "/windows_compute/_Blueprint/#target-release",
            "text": "For release 1: 5.0\nFor release 2+: tbd",
            "title": "Target Release"
        },
        {
            "location": "/windows_compute/_Blueprint/#user-visible-changes",
            "text": "On Linux, none.\nOn Windows, one can use Windows docker command line tools to spawn Windows containers and connect them to Contrail networks. (orchestration is not in scope of release 1)\nFor deployment, MSI installers are provided.",
            "title": "User-visible changes"
        },
        {
            "location": "/windows_compute/_Blueprint/#internal-changes",
            "text": "3 components are affected:    Windows docker driver is added. It is roughly equivalent to Nova Agent, but runs as a Windows service and implements docker driver APIs. It communicates with config, Agent and HNS (Host Network Service - Windows container management service). Written in Golang.    vRouter Agent. Parts of the codebase are not cross platform. Changes involve rewriting those and fixing related bugs.    vRouter Forwarding Extension. Implements vRouter kernel module functionality in terms of a Hyper-V Forwarding Extension, which is basically a kernel mode \"plugin\" for Windows virtual switch.    Linux communication channels between (2) and (3) are also ported using Named Pipes (for ksync and pkt0) and Windows shared memory (for flow).  More info is available under spec url.",
            "title": "Internal changes"
        },
        {
            "location": "/windows_compute/vRouter_Linux_implementation/",
            "text": "On Linux, vRouter implementation consists of two parts: a userspace agent and a kernel module, along with all the userspace utility command line tools. The agent communicates with OpenContrail\u2019s control nodes and receives configuration state, like forwarding information. Its main responsibility is installation of forwarding state into the kernel module.\n\n\nFunctionality of the data plane, like flow tables, is contained in dp-core component. Translation between the agent\u2019s object model and low-level data model used by datapath is realized by the KSync module, which is utilized by both the agent and the kernel module.\n\n\nOn Linux, communication between the forwarding plane, which runs in kernel space, and the user space agent, is done via use of Netlink sockets and shared memory. However, neither BSD nor Windows support Netlink sockets. That\u2019s why, on FreeBSD, they are emulated over raw sockets.",
            "title": "vRouter Linux implementation"
        }
    ]
}